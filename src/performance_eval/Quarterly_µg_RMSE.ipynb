{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76784d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated quarterly predictions saved to: Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\aggregated_quarterly_µg_prediction_errors.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "input_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\sfc_row_level_predictions_2023_v0063_H3res4.csv\"\n",
    "output_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\aggregated_quarterly_µg_prediction_errors.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert 'Month' column (assumed format 'YYYY-MM') to datetime\n",
    "df['Month_dt'] = pd.to_datetime(df['Month'], format=\"%Y-%m\", errors='coerce')\n",
    "\n",
    "# Define a function to map month to the custom quarter\n",
    "def map_month_to_quarter(dt):\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    month = dt.month\n",
    "    # Q1 = DJF: December, January, February\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'DJF'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'MAM'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'JJA'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'SON'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create a new 'Quarter' column\n",
    "df['Quarter'] = df['Month_dt'].apply(map_month_to_quarter)\n",
    "\n",
    "# Convert from kg/m³ to µg/m³ (1 kg = 1e9 µg)\n",
    "df['DUSMASS_mean_ugm3'] = df['DUSMASS_mean'] * 1e9\n",
    "df['ensemble_predictions_ugm3'] = df['ensemble_predictions'] * 1e9\n",
    "\n",
    "# Compute the per-row difference (observed - predicted)\n",
    "df['Diff_error'] = df['DUSMASS_mean_ugm3'] - df['ensemble_predictions_ugm3']\n",
    "\n",
    "# Group by hexagon (h3_res_4) and Quarter for spatial and temporal aggregation\n",
    "grouped = df.groupby(['h3_res_4', 'Quarter'])\n",
    "\n",
    "# Define a function to aggregate error metrics for each group\n",
    "def aggregate_errors(group):\n",
    "    # Observed and predicted values in µg/m³\n",
    "    obs = group['DUSMASS_mean_ugm3']\n",
    "    pred = group['ensemble_predictions_ugm3']\n",
    "    diff = obs - pred\n",
    "    \n",
    "    # Compute aggregated metrics\n",
    "    mean_obs = obs.mean()\n",
    "    mean_pred = pred.mean()\n",
    "    mean_diff = diff.mean()             # Aggregated Diff_error (mean difference)\n",
    "    mse = np.mean(diff**2)               # Mean Squared Error over the group\n",
    "    mae = np.mean(np.abs(diff))          # Mean Absolute Error over the group\n",
    "    rmse = np.sqrt(mse)                  # Root Mean Squared Error over the group\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Mean_DUSMASS_mean_ugm3': mean_obs,\n",
    "        'Mean_ensemble_predictions_ugm3': mean_pred,\n",
    "        'Diff_error': mean_diff,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'sample_size': group.shape[0]  # Optional: number of observations in the group\n",
    "    })\n",
    "\n",
    "# Apply the aggregation function to each group\n",
    "agg_df = grouped.apply(aggregate_errors).reset_index()\n",
    "\n",
    "# Optionally rearrange columns\n",
    "agg_df = agg_df[['h3_res_4', 'Quarter', 'sample_size',\n",
    "                 'Mean_DUSMASS_mean_ugm3', 'Mean_ensemble_predictions_ugm3',\n",
    "                 'Diff_error', 'MSE', 'MAE', 'RMSE']]\n",
    "\n",
    "# Save the aggregated results to a new CSV file\n",
    "agg_df.to_csv(output_path, index=False)\n",
    "print(\"Aggregated quarterly predictions saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8007be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated quarterly predictions with original columns saved to: Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\SFC_aggregated_quarterly_µg_prediction_errors2.csv\n"
     ]
    }
   ],
   "source": [
    "#Surface\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "input_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\sfc_row_level_predictions_2023_v0063_H3res4.csv\"\n",
    "output_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\SFC\\DC_v0063\\SFC_aggregated_quarterly_µg_prediction_errors2.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert 'Month' column (assumed format 'YYYY-MM') to datetime\n",
    "df['Month_dt'] = pd.to_datetime(df['Month'], format=\"%Y-%m\", errors='coerce')\n",
    "\n",
    "# Define a function to map month to the custom quarter\n",
    "def map_month_to_quarter(dt):\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    month = dt.month\n",
    "    # Q1 = DJF: December, January, February\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'DJF'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'MAM'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'JJA'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'SON'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a new 'Quarter' column based on the Month_dt column\n",
    "df['Quarter'] = df['Month_dt'].apply(map_month_to_quarter)\n",
    "\n",
    "# Convert from kg/m³ to µg/m³ (1 kg = 1e9 µg)\n",
    "df['DUSMASS_mean_ugm3'] = df['DUSMASS_mean'] * 1e9\n",
    "df['ensemble_predictions_ugm3'] = df['ensemble_predictions'] * 1e9\n",
    "\n",
    "# Compute the per-row difference (observed - predicted)\n",
    "df['Diff_error'] = df['DUSMASS_mean_ugm3'] - df['ensemble_predictions_ugm3']\n",
    "\n",
    "# Group by hexagon (h3_res_4) and Quarter for spatial and temporal aggregation\n",
    "grouped = df.groupby(['h3_res_4', 'Quarter'])\n",
    "\n",
    "# Define a function to aggregate error metrics for each group.\n",
    "# Aggregated metrics get the prefix \"agg_\" to distinguish them from row-level values.\n",
    "def aggregate_errors(group):\n",
    "    obs = group['DUSMASS_mean_ugm3']\n",
    "    pred = group['ensemble_predictions_ugm3']\n",
    "    diff = obs - pred\n",
    "    \n",
    "    # Compute aggregated metrics\n",
    "    mean_obs = obs.mean()\n",
    "    mean_pred = pred.mean()\n",
    "    mean_diff = diff.mean()       # Aggregated Diff_error (mean difference)\n",
    "    mse = np.mean(diff**2)         # Mean Squared Error over the group\n",
    "    mae = np.mean(np.abs(diff))    # Mean Absolute Error over the group\n",
    "    rmse = np.sqrt(mse)            # Root Mean Squared Error over the group\n",
    "    \n",
    "    return pd.Series({\n",
    "        'agg_Mean_DUSMASS_mean_ugm3': mean_obs,\n",
    "        'agg_Mean_ensemble_predictions_ugm3': mean_pred,\n",
    "        'agg_Diff_error': mean_diff,\n",
    "        'agg_MSE': mse,\n",
    "        'agg_MAE': mae,\n",
    "        'agg_RMSE': rmse,\n",
    "        'sample_size': group.shape[0]  # Number of observations in the group\n",
    "    })\n",
    "\n",
    "# Apply the aggregation function to each group\n",
    "agg_df = grouped.apply(aggregate_errors).reset_index()\n",
    "\n",
    "# Merge the aggregated metrics back to the original DataFrame.\n",
    "# Every row will have the aggregated metrics corresponding to its hexagon and quarter.\n",
    "merged_df = pd.merge(df, agg_df, on=['h3_res_4', 'Quarter'], how='left')\n",
    "\n",
    "# (Optional) Rearrange columns so that the original data appears first, followed by aggregated metrics.\n",
    "cols_order = [\n",
    "    'lon', 'lat', 'time', 'DUSMASS_mean', 'Month', 'lag_1', 'ensemble_predictions',\n",
    "    'Country', 'h3_res_3', 'h3_res_4', 'Month_dt', 'Quarter',\n",
    "    'DUSMASS_mean_ugm3', 'ensemble_predictions_ugm3', 'Diff_error',\n",
    "    'agg_Mean_DUSMASS_mean_ugm3', 'agg_Mean_ensemble_predictions_ugm3', \n",
    "    'agg_Diff_error', 'agg_MSE', 'agg_MAE', 'agg_RMSE', 'sample_size'\n",
    "]\n",
    "cols_order = [col for col in cols_order if col in merged_df.columns]\n",
    "merged_df = merged_df[cols_order]\n",
    "\n",
    "# Save the merged results to a new CSV file\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(\"Aggregated quarterly predictions with original columns saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859e0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated quarterly predictions with original columns saved to: Z:\\Thesis\\Data\\test\\DustCast\\UA\\DC_v0063\\UA_aggregated_quarterly_µg_prediction_errors2.csv\n"
     ]
    }
   ],
   "source": [
    "#upper atmosphere\n",
    "\n",
    "#Surface\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "input_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\UA\\DC_v0063\\ua_level_averages_2023_v0063_H3res4_test.csv\"\n",
    "output_path = r\"Z:\\Thesis\\Data\\test\\DustCast\\UA\\DC_v0063\\UA_aggregated_quarterly_µg_prediction_errors2.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert 'Month' column (assumed format 'YYYY-MM') to datetime\n",
    "df['Month_dt'] = pd.to_datetime(df['Month'], format=\"%Y-%m\", errors='coerce')\n",
    "\n",
    "# Define a function to map month to the custom quarter\n",
    "def map_month_to_quarter(dt):\n",
    "    if pd.isnull(dt):\n",
    "        return None\n",
    "    month = dt.month\n",
    "    # Q1 = DJF: December, January, February\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'DJF'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'MAM'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'JJA'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'SON'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a new 'Quarter' column based on the Month_dt column\n",
    "df['Quarter'] = df['Month_dt'].apply(map_month_to_quarter)\n",
    "\n",
    "# Convert from kg/m³ to µg/m³ (1 kg = 1e9 µg)\n",
    "df['DUCMASS_mean_ugm3'] = df['DUCMASS_mean'] * 1e9\n",
    "df['ensemble_predictions_ugm3'] = df['ensemble_predictions'] * 1e9\n",
    "\n",
    "# Compute the per-row difference (observed - predicted)\n",
    "df['Diff_error'] = df['DUCMASS_mean_ugm3'] - df['ensemble_predictions_ugm3']\n",
    "\n",
    "# Group by hexagon (h3_res_4) and Quarter for spatial and temporal aggregation\n",
    "grouped = df.groupby(['h3_res_4', 'Quarter'])\n",
    "\n",
    "# Define a function to aggregate error metrics for each group.\n",
    "# Aggregated metrics get the prefix \"agg_\" to distinguish them from row-level values.\n",
    "def aggregate_errors(group):\n",
    "    obs = group['DUCMASS_mean_ugm3']\n",
    "    pred = group['ensemble_predictions_ugm3']\n",
    "    diff = obs - pred\n",
    "    \n",
    "    # Compute aggregated metrics\n",
    "    mean_obs = obs.mean()\n",
    "    mean_pred = pred.mean()\n",
    "    mean_diff = diff.mean()       # Aggregated Diff_error (mean difference)\n",
    "    mse = np.mean(diff**2)         # Mean Squared Error over the group\n",
    "    mae = np.mean(np.abs(diff))    # Mean Absolute Error over the group\n",
    "    rmse = np.sqrt(mse)            # Root Mean Squared Error over the group\n",
    "    \n",
    "    return pd.Series({\n",
    "        'agg_Mean_DUCMASS_mean_ugm3': mean_obs,\n",
    "        'agg_Mean_ensemble_predictions_ugm3': mean_pred,\n",
    "        'agg_Diff_error': mean_diff,\n",
    "        'agg_MSE': mse,\n",
    "        'agg_MAE': mae,\n",
    "        'agg_RMSE': rmse,\n",
    "        'sample_size': group.shape[0]  # Number of observations in the group\n",
    "    })\n",
    "\n",
    "# Apply the aggregation function to each group\n",
    "agg_df = grouped.apply(aggregate_errors).reset_index()\n",
    "\n",
    "# Merge the aggregated metrics back to the original DataFrame.\n",
    "# Every row will have the aggregated metrics corresponding to its hexagon and quarter.\n",
    "merged_df = pd.merge(df, agg_df, on=['h3_res_4', 'Quarter'], how='left')\n",
    "\n",
    "# (Optional) Rearrange columns so that the original data appears first, followed by aggregated metrics.\n",
    "cols_order = [\n",
    "    'lon', 'lat', 'time', 'DUCMASS_mean', 'Month', 'lag_1', 'ensemble_predictions',\n",
    "    'h3_res_3', 'h3_res_4', 'Month_dt', 'Quarter', #'Country',\n",
    "    'DUCMASS_mean_ugm3', 'ensemble_predictions_ugm3', 'Diff_error',\n",
    "    'agg_Mean_DUCMASS_mean_ugm3', 'agg_Mean_ensemble_predictions_ugm3', \n",
    "    'agg_Diff_error', 'agg_MSE', 'agg_MAE', 'agg_RMSE', 'sample_size'\n",
    "]\n",
    "cols_order = [col for col in cols_order if col in merged_df.columns]\n",
    "merged_df = merged_df[cols_order]\n",
    "\n",
    "# Save the merged results to a new CSV file\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(\"Aggregated quarterly predictions with original columns saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5ed4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
