{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a6da4-dd26-4165-a0c1-12d8de7b7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify Parquet files\n",
    "# Add pressure_level column with 1013mb entry for sfc data\n",
    "# remove extra number and expver columns if they exist\n",
    "# Convert surface NetCDF files to parquet\n",
    "\n",
    "# Import libs\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the root dir where the NetCDF files are located\n",
    "root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5\"\n",
    "\n",
    "# Define the years to process\n",
    "years = [str(year) for year in range(2019, 2024)]\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\n",
    "    #\"Bahrain\",\n",
    "    \"Kuwait\",\n",
    "    #\"Oman\",\n",
    "    #\"Qatar\",\n",
    "    #\"Saudi Arabia\", \n",
    "    #\"United Arab Emirates\",\n",
    "    #\"Yemen\"\n",
    "]\n",
    "\n",
    "# Define the subfolders to process\n",
    "subfolders = [\"surface\"]\n",
    "\n",
    "# Define the output root dir for parquet files\n",
    "output_root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# collect all NetCDF files into a list\n",
    "netcdf_files = []\n",
    "\n",
    "# Iterate through the years\n",
    "for year in years:\n",
    "    year_dir = os.path.join(root_dir, year)\n",
    "    # Iterate through the countries\n",
    "    for country in countries:\n",
    "        country_dir = os.path.join(year_dir, country)\n",
    "        # Iterate through subfolders\n",
    "        for subfolder in subfolders:\n",
    "            # Define the subfolder directory\n",
    "            subfolder_dir = os.path.join(country_dir, subfolder)\n",
    "            # Check if the subfolder exists\n",
    "            if not os.path.exists(subfolder_dir):\n",
    "                continue\n",
    "            # Get a list of NEtCDF files inthe subfolder\n",
    "            files_in_subfolder = [\n",
    "                os.path.join(subfolder_dir, f) for f in os.listdir(subfolder_dir) if f.endswith('.nc')\n",
    "            ]\n",
    "            # Add the files to the list\n",
    "            netcdf_files.extend(files_in_subfolder)\n",
    "\n",
    "\n",
    "# Process the files with a progress bar\n",
    "for netcdf_path in tqdm(netcdf_files, desc=\"Processing files\"):\n",
    "    # Print the file being prcessed\n",
    "    tqdm.write(f\"Processing file: {netcdf_path}\")\n",
    "    # Read the NEtCDF file using xarray\n",
    "    try:\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error reading {netcdf_path: {e}}\")\n",
    "        continue\n",
    "\n",
    "    # Convert xarray dataset to pandas DataFrame\n",
    "    try:\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        # Inspect 'valid_time'\n",
    "        print(f\"Before conversion - Data type of 'time': {df['time'].dtype}\")\n",
    "        print(f\"Sample 'time' values:\\n{df['time'].head()}\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error converting dataset to DataFrame for {netcdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if the file is in a 'surface' subfolder to add 'pressure_level'\n",
    "    if os.path.normpath('surface') in os.path.normpath(netcdf_path).split(os.sep):\n",
    "        df['pressure_level'] = 1013.0\n",
    "        # Ensure 'pressure_level' is in the second column after 'valid_time\n",
    "        cols = df.columns.tolist()\n",
    "        if 'time' in cols and 'pressure_level' in cols:\n",
    "            cols.insert(cols.index('time') + 1, cols.pop(cols.index('pressure_level')))\n",
    "            df = df[cols]\n",
    "\n",
    "    # Cechk if 'valid_time' is in Unix timestamp format and convert to timestampz\n",
    "    if pd.api.types.is_integer_dtype(df['time']):\n",
    "        try:\n",
    "            # convert 'valid_time' from Unix timestamp to datetime\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error converting 'time' to datetime for {netcdf_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Define the output directory\n",
    "    relative_path = os.path.relpath(netcdf_path, root_dir)\n",
    "    output_dir = os.path.join(output_root_dir, os.path.dirname(relative_path))\n",
    "    # Create the output directory if it doesnt exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Define the output file name\n",
    "    netcdf_file = os.path.basename(netcdf_path)\n",
    "    parquet_file = netcdf_file.replace('.nc', '.parquet')\n",
    "    parquet_path = os.path.join(output_dir, parquet_file)\n",
    "\n",
    "    # Write the DataFrame to a Parquet file\n",
    "    try:\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        tqdm.write(f\"Successfully converted {netcdf_path} to {parquet_path}\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error writing Parquet file for {netcdf_path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f04bb-40fc-4350-80e2-a8e9fda35cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify Parquet files\n",
    "# Add pressure_level column with 1013mb entry for sfc data\n",
    "# remove extra number and expver columns if they exist\n",
    "# Convert surface NetCDF files to parquet\n",
    "\n",
    "# Import libs\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the root dir where the NetCDF files are located\n",
    "root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5\"\n",
    "\n",
    "# Define the years to process\n",
    "years = [str(year) for year in range(2017, 2018)]\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\n",
    "    \"Bahrain\",\n",
    "    \"Kuwait\",\n",
    "    \"Oman\",\n",
    "    \"Qatar\",\n",
    "    \"Saudi Arabia\", \n",
    "    \"United Arab Emirates\",\n",
    "    \"Yemen\"\n",
    "]\n",
    "\n",
    "# Define the subfolders to process\n",
    "subfolders = [\"pressure\"]\n",
    "\n",
    "# Define the output root dir for parquet files\n",
    "output_root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# collect all NetCDF files into a list\n",
    "netcdf_files = []\n",
    "\n",
    "# Iterate through the years\n",
    "for year in years:\n",
    "    year_dir = os.path.join(root_dir, year)\n",
    "    # Iterate through the countries\n",
    "    for country in countries:\n",
    "        country_dir = os.path.join(year_dir, country)\n",
    "        # Iterate through subfolders\n",
    "        for subfolder in subfolders:\n",
    "            # Define the subfolder directory\n",
    "            subfolder_dir = os.path.join(country_dir, subfolder)\n",
    "            # Check if the subfolder exists\n",
    "            if not os.path.exists(subfolder_dir):\n",
    "                continue\n",
    "            # Get a list of NEtCDF files inthe subfolder\n",
    "            files_in_subfolder = [\n",
    "                os.path.join(subfolder_dir, f) for f in os.listdir(subfolder_dir) if f.endswith('.nc')\n",
    "            ]\n",
    "            # Add the files to the list\n",
    "            netcdf_files.extend(files_in_subfolder)\n",
    "\n",
    "\n",
    "# Process the files with a progress bar\n",
    "for netcdf_path in tqdm(netcdf_files, desc=\"Processing files\"):\n",
    "    # Print the file being prcessed\n",
    "    tqdm.write(f\"Processing file: {netcdf_path}\")\n",
    "    # Read the NEtCDF file using xarray\n",
    "    try:\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error reading {netcdf_path: {e}}\")\n",
    "        continue\n",
    "\n",
    "        #\n",
    "        # Convert xarray dataset to pandas DataFrame\n",
    "        try:\n",
    "            df = ds.to_dataframe().reset_index()\n",
    "    \n",
    "            # Dynamically handle 'time' or 'valid_time'\n",
    "            time_column = 'time' if 'time' in df.columns else 'valid_time' if 'valid_time' in df.columns else None\n",
    "    \n",
    "            if time_column:\n",
    "               print(f\"Before conversion - Data type of '{time_column}': {df[time_column].dtype}\")\n",
    "               print(f\"Sample '{time_column}' values:\\n{df[time_column].head()}\")\n",
    "            else:\n",
    "                tqdm.write(f\"No 'time' or 'valid_time' column found in {netcdf_path}. Skipping.\")\n",
    "                continue  # Skip files without either column\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error converting dataset to DataFrame for {netcdf_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    # Convert xarray dataset to pandas DataFrame\n",
    "    #try:\n",
    "    #    df = ds.to_dataframe().reset_index()\n",
    "        # Inspect 'valid_time'\n",
    "   #     print(f\"Before conversion - Data type of 'time': {df['time'].dtype}\")\n",
    "   #     print(f\"Sample 'time' values:\\n{df['time'].head()}\")\n",
    "   # except Exception as e:\n",
    "   #     tqdm.write(f\"Error converting dataset to DataFrame for {netcdf_path}: {e}\")\n",
    "        #continue\n",
    "    \n",
    "    # Check if the file is in a 'surface' subfolder to add 'pressure_level'\n",
    "    #if os.path.normpath('surface') in os.path.normpath(netcdf_path).split(os.sep):\n",
    "     #   df['pressure_level'] = 1013.0\n",
    "     #   # Ensure 'pressure_level' is in the second column after 'valid_time\n",
    "     #   cols = df.columns.tolist()\n",
    "     #   if 'time' in cols and 'pressure_level' in cols:\n",
    "     #       cols.insert(cols.index('time') + 1, cols.pop(cols.index('pressure_level')))\n",
    "     #       df = df[cols]\n",
    "    # Check if the file is in a 'surface' subfolder to add 'pressure_level'\n",
    "    if os.path.normpath('surface') in os.path.normpath(netcdf_path).split(os.sep):\n",
    "        df['pressure_level'] = 1013.0\n",
    "\n",
    "        # Ensure 'pressure_level' is in the second column after the time-related column\n",
    "        cols = df.columns.tolist()\n",
    "        time_column = 'time' if 'time' in cols else 'valid_time' if 'valid_time' in cols else None\n",
    "    \n",
    "        if time_column and 'pressure_level' in cols:\n",
    "            cols.insert(cols.index(time_column) + 1, cols.pop(cols.index('pressure_level')))\n",
    "            df = df[cols]\n",
    "        else:\n",
    "            tqdm.write(f\"Skipping file {netcdf_path}: No valid time-related column found.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    # Cechk if 'valid_time' is in Unix timestamp format and convert to timestampz\n",
    "    #if pd.api.types.is_integer_dtype(df['time']):\n",
    "     #   try:\n",
    "            # convert 'valid_time' from Unix timestamp to datetime\n",
    "      #      df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "       # except Exception as e:\n",
    "        #    tqdm.write(f\"Error converting 'time' to datetime for {netcdf_path}: {e}\")\n",
    "         #   continue\n",
    "\n",
    "    # Check if 'time' or 'valid_time' is in Unix timestamp format and convert to datetime\n",
    "    time_column = 'time' if 'time' in df.columns else 'valid_time' if 'valid_time' in df.columns else None\n",
    "\n",
    "    if time_column:\n",
    "        if pd.api.types.is_integer_dtype(df[time_column]):\n",
    "            try:\n",
    "                # Convert Unix timestamp to datetime\n",
    "                df[time_column] = pd.to_datetime(df[time_column], unit='s', utc=True)\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error converting '{time_column}' to datetime for {netcdf_path}: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        tqdm.write(f\"Skipping file {netcdf_path}: No valid time-related column found.\")\n",
    "        continue\n",
    "\n",
    "    # Define the output directory\n",
    "    relative_path = os.path.relpath(netcdf_path, root_dir)\n",
    "    output_dir = os.path.join(output_root_dir, os.path.dirname(relative_path))\n",
    "    # Create the output directory if it doesnt exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Define the output file name\n",
    "    netcdf_file = os.path.basename(netcdf_path)\n",
    "    parquet_file = netcdf_file.replace('.nc', '.parquet')\n",
    "    parquet_path = os.path.join(output_dir, parquet_file)\n",
    "\n",
    "    # Write the DataFrame to a Parquet file\n",
    "    try:\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        tqdm.write(f\"Successfully converted {netcdf_path} to {parquet_path}\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error writing Parquet file for {netcdf_path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443c896-d305-4c18-a8fe-a9deef3bb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the root dir where the NetCDF files are located\n",
    "root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5\"\n",
    "\n",
    "# Define the years to process\n",
    "years = [str(year) for year in range(2017, 2018)]\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\n",
    "    \"Bahrain\",\n",
    "    \"Kuwait\",\n",
    "    \"Oman\",\n",
    "    \"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"United Arab Emirates\",\n",
    "    \"Yemen\"\n",
    "]\n",
    "\n",
    "# Define the subfolders to process\n",
    "subfolders = [\"surface\", \"pressure\"] #pressure\n",
    "\n",
    "# Define the output root dir for parquet files\n",
    "output_root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# Collect all NetCDF files into a list\n",
    "netcdf_files = []\n",
    "\n",
    "# List to store skipped files and error messages\n",
    "skipped_files = []\n",
    "\n",
    "# Iterate through the years\n",
    "for year in years:\n",
    "    year_dir = os.path.join(root_dir, year)\n",
    "    for country in countries:\n",
    "        country_dir = os.path.join(year_dir, country)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_dir = os.path.join(country_dir, subfolder)\n",
    "            if not os.path.exists(subfolder_dir):\n",
    "                continue\n",
    "            files_in_subfolder = [\n",
    "                os.path.join(subfolder_dir, f) for f in os.listdir(subfolder_dir) if f.endswith('.nc')\n",
    "            ]\n",
    "            netcdf_files.extend(files_in_subfolder)\n",
    "\n",
    "# Process the files with a progress bar\n",
    "for netcdf_path in tqdm(netcdf_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Print the file being processed\n",
    "        tqdm.write(f\"Processing file: {netcdf_path}\")\n",
    "        \n",
    "        # Read the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "        \n",
    "        # Convert xarray dataset to pandas DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        \n",
    "        # Dynamically handle 'time' or 'valid_time'\n",
    "        time_column = 'time' if 'time' in df.columns else 'valid_time' if 'valid_time' in df.columns else None\n",
    "        if not time_column:\n",
    "            raise ValueError(\"No 'time' or 'valid_time' column found\")\n",
    "        \n",
    "        # If the file is in a 'surface' subfolder, add 'pressure_level'\n",
    "        if os.path.normpath('surface') in os.path.normpath(netcdf_path).split(os.sep):\n",
    "            df['pressure_level'] = 1013.0\n",
    "            cols = df.columns.tolist()\n",
    "            if time_column in cols and 'pressure_level' in cols:\n",
    "                cols.insert(cols.index(time_column) + 1, cols.pop(cols.index('pressure_level')))\n",
    "                df = df[cols]\n",
    "        \n",
    "        # Define the output directory and file path\n",
    "        relative_path = os.path.relpath(netcdf_path, root_dir)\n",
    "        output_dir = os.path.join(output_root_dir, os.path.dirname(relative_path))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        parquet_file = os.path.basename(netcdf_path).replace('.nc', '.parquet')\n",
    "        parquet_path = os.path.join(output_dir, parquet_file)\n",
    "        \n",
    "        # Write the DataFrame to a Parquet file\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        tqdm.write(f\"Successfully converted {netcdf_path} to {parquet_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Add the file and error to the skipped files list\n",
    "        skipped_files.append((netcdf_path, str(e)))\n",
    "        tqdm.write(f\"Error processing {netcdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Print the summary of skipped files\n",
    "if skipped_files:\n",
    "    print(\"\\nSummary of Skipped Files:\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\"{file}: {error}\")\n",
    "\n",
    "    # Optionally save the skipped files to a CSV for further investigation\n",
    "    skipped_df = pd.DataFrame(skipped_files, columns=[\"File Path\", \"Error Message\"])\n",
    "    skipped_df.to_csv(os.path.join(output_root_dir, \"skipped_files.csv\"), index=False)\n",
    "    print(f\"Skipped files list saved to {os.path.join(output_root_dir, 'skipped_files.csv')}\")\n",
    "else:\n",
    "    print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71517cd4-5448-4879-ba6e-409e2d4af938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|                                      | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_u_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|                                      | 0/66 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'level' column with value 1013.0 for surface file: Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_u_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|                                      | 0/66 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing levels in Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_u_component_of_wind.nc: {100, 1000, 200, 10, 300, 850, 50, 500, 700, 925}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   2%|▍                             | 1/66 [00:08<09:03,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_u_component_of_wind.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1980\\Saudi_Arabia\\surface\\1980_Saudi Arabia_surface_10m_u_component_of_wind.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_v_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   2%|▍                             | 1/66 [00:11<09:03,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'level' column with value 1013.0 for surface file: Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_v_component_of_wind.nc\n",
      "Warning: Missing levels in Z:\\Thesis\\Data\\Met\\ERA5\\1980\\Saudi Arabia\\surface\\1980_Saudi Arabia_surface_10m_v_component_of_wind.nc: {100, 1000, 200, 10, 300, 850, 50, 500, 700, 925}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the root dir where the NetCDF files are located\n",
    "root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5\"\n",
    "\n",
    "# Define the years to process\n",
    "years = [str(year) for year in range(1980, 1981)]\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\n",
    "    #\"Bahrain\",\n",
    "    #\"Kuwait\",\n",
    "    #\"Oman\",\n",
    "    #\"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"United Arab Emirates\",\n",
    "    #\"Yemen\"\n",
    "]\n",
    "\n",
    "# Define the subfolders to process\n",
    "subfolders = [\"surface\", \"pressure\"]\n",
    "\n",
    "# Define the output root dir for parquet files\n",
    "output_root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# Function to adjust country names for output folder\n",
    "def adjust_country_name(country):\n",
    "    if country == \"Saudi Arabia\":\n",
    "        return \"Saudi_Arabia\"\n",
    "    elif country == \"United Arab Emirates\":\n",
    "        return \"United_Arab_Emirates\"\n",
    "    return country\n",
    "\n",
    "# Collect all NetCDF files into a list\n",
    "netcdf_files = []\n",
    "\n",
    "# List to store skipped files and error messages\n",
    "skipped_files = []\n",
    "\n",
    "# Iterate through the years\n",
    "for year in years:\n",
    "    year_dir = os.path.join(root_dir, year)\n",
    "    for country in countries:\n",
    "        country_dir = os.path.join(year_dir, country)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_dir = os.path.join(country_dir, subfolder)\n",
    "            if not os.path.exists(subfolder_dir):\n",
    "                continue\n",
    "            files_in_subfolder = [\n",
    "                os.path.join(subfolder_dir, f) for f in os.listdir(subfolder_dir) if f.endswith('.nc')\n",
    "            ]\n",
    "            netcdf_files.extend(files_in_subfolder)\n",
    "\n",
    "# Process the files with a progress bar\n",
    "for netcdf_path in tqdm(netcdf_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Print the file being processed\n",
    "        tqdm.write(f\"Processing file: {netcdf_path}\")\n",
    "        \n",
    "        # Read the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "        \n",
    "        # Convert xarray dataset to pandas DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        \n",
    "        # Check for 'level' or 'pressure_level' and standardize the column name to 'level'\n",
    "        if 'pressure_level' in df.columns:\n",
    "            df.rename(columns={'pressure_level': 'level'}, inplace=True)\n",
    "            tqdm.write(f\"Renamed 'pressure_level' to 'level' for file: {netcdf_path}\")\n",
    "        elif 'level' not in df.columns:\n",
    "            # If neither column exists, handle surface or raise an error\n",
    "            if 'surface' in os.path.normpath(netcdf_path).split(os.sep):\n",
    "                df['level'] = 1013.0  # Add a 'level' column for surface files\n",
    "                tqdm.write(f\"Added 'level' column with value 1013.0 for surface file: {netcdf_path}\")\n",
    "            else:\n",
    "                raise ValueError(\"'level' column is missing in the pressure file\")\n",
    "        \n",
    "        # Verify all levels are present for pressure files\n",
    "        expected_levels = [1000, 925, 850, 700, 500, 300, 200, 100, 50, 10]\n",
    "        if 'level' in df.columns:\n",
    "            missing_levels = set(expected_levels) - set(df['level'].unique())\n",
    "            if missing_levels:\n",
    "                tqdm.write(f\"Warning: Missing levels in {netcdf_path}: {missing_levels}\")\n",
    "        \n",
    "        # Dynamically handle 'time' or 'valid_time'\n",
    "        time_column = 'time' if 'time' in df.columns else 'valid_time' if 'valid_time' in df.columns else None\n",
    "        if not time_column:\n",
    "            raise ValueError(\"No 'time' or 'valid_time' column found\")\n",
    "        \n",
    "        # Adjust the country name for output folder\n",
    "        relative_path = os.path.relpath(netcdf_path, root_dir)\n",
    "        parts = relative_path.split(os.sep)\n",
    "        if len(parts) >= 2:\n",
    "            parts[1] = adjust_country_name(parts[1])  # Adjust country name if needed\n",
    "        adjusted_relative_path = os.path.join(*parts)\n",
    "        \n",
    "        # Define the output directory and file path\n",
    "        output_dir = os.path.join(output_root_dir, os.path.dirname(adjusted_relative_path))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        parquet_file = os.path.basename(netcdf_path).replace('.nc', '.parquet')\n",
    "        parquet_path = os.path.join(output_dir, parquet_file)\n",
    "        \n",
    "        # Write the DataFrame to a Parquet file\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        tqdm.write(f\"Successfully converted {netcdf_path} to {parquet_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Add the file and error to the skipped files list\n",
    "        skipped_files.append((netcdf_path, str(e)))\n",
    "        tqdm.write(f\"Error processing {netcdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Print the summary of skipped files\n",
    "if skipped_files:\n",
    "    print(\"\\nSummary of Skipped Files:\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\"{file}: {error}\")\n",
    "\n",
    "    # Optionally save the skipped files to a CSV for further investigation\n",
    "    skipped_df = pd.DataFrame(skipped_files, columns=[\"File Path\", \"Error Message\"])\n",
    "    skipped_df.to_csv(os.path.join(output_root_dir, \"skipped_files.csv\"), index=False)\n",
    "    print(f\"Skipped files list saved to {os.path.join(output_root_dir, 'skipped_files.csv')}\")\n",
    "else:\n",
    "    print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce120ef2-ee57-489a-a2d8-1a19cde5bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|                                       | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_geopotential.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|                                       | 0/7 [00:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_geopotential.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  14%|████▎                         | 1/7 [01:47<10:44, 107.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_geopotential.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_geopotential.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_relative_humidity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  14%|████▎                         | 1/7 [03:12<10:44, 107.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_relative_humidity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  29%|████████▌                     | 2/7 [04:18<11:04, 132.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_relative_humidity.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_relative_humidity.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_temperature.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  29%|████████▌                     | 2/7 [05:37<11:04, 132.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_temperature.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████████████▊                 | 3/7 [06:40<09:09, 137.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_temperature.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_temperature.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_u_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████████████▊                 | 3/7 [07:55<09:09, 137.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_u_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  57%|█████████████████▏            | 4/7 [08:58<06:52, 137.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_u_component_of_wind.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_u_component_of_wind.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vertical_velocity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  57%|█████████████████▏            | 4/7 [10:07<06:52, 137.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vertical_velocity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  71%|█████████████████████▍        | 5/7 [11:08<04:29, 134.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vertical_velocity.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_vertical_velocity.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vorticity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  71%|█████████████████████▍        | 5/7 [12:16<04:29, 134.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vorticity.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|█████████████████████████▋    | 6/7 [13:20<02:13, 133.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_vorticity.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_vorticity.parquet\n",
      "Processing file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_v_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|█████████████████████████▋    | 6/7 [14:25<02:13, 133.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pressure_level' to 'level' for file: Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_v_component_of_wind.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████| 7/7 [15:27<00:00, 132.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted Z:\\Thesis\\Data\\Met\\ERA5\\1996\\Saudi Arabia\\pressure\\1996_Saudi Arabia_pressure_v_component_of_wind.nc to Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1996\\Saudi_Arabia\\pressure\\1996_Saudi_Arabia_pressure_v_component_of_wind.parquet\n",
      "\n",
      "All files processed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the root dir where the NetCDF files are located\n",
    "root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5\"\n",
    "\n",
    "# Define the years to process\n",
    "years = [str(year) for year in range(1996, 1997)]\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\n",
    "    #\"Bahrain\",\n",
    "    #\"Kuwait\",\n",
    "    #\"Oman\",\n",
    "    #\"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    #\"United Arab Emirates\",\n",
    "    #\"Yemen\"\n",
    "]\n",
    "# Define the subfolders to process\n",
    "subfolders = [#\"surface\",\n",
    "              \"pressure\"\n",
    "             ]\n",
    "\n",
    "# Define the output root dir for parquet files\n",
    "output_root_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# Function to adjust country names for output folder\n",
    "def adjust_country_name(country):\n",
    "    if country == \"Saudi Arabia\":\n",
    "        return \"Saudi_Arabia\"\n",
    "    elif country == \"United Arab Emirates\":\n",
    "        return \"United_Arab_Emirates\"\n",
    "    return country\n",
    "\n",
    "# Collect all NetCDF files into a list\n",
    "netcdf_files = []\n",
    "\n",
    "# List to store skipped files and error messages\n",
    "skipped_files = []\n",
    "\n",
    "# Iterate through the years\n",
    "for year in years:\n",
    "    year_dir = os.path.join(root_dir, year)\n",
    "    for country in countries:\n",
    "        country_dir = os.path.join(year_dir, country)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_dir = os.path.join(country_dir, subfolder)\n",
    "            if not os.path.exists(subfolder_dir):\n",
    "                continue\n",
    "            files_in_subfolder = [\n",
    "                os.path.join(subfolder_dir, f) for f in os.listdir(subfolder_dir) if f.endswith('.nc')\n",
    "            ]\n",
    "            netcdf_files.extend(files_in_subfolder)\n",
    "\n",
    "# Process the files with a progress bar\n",
    "for netcdf_path in tqdm(netcdf_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Print the file being processed\n",
    "        tqdm.write(f\"Processing file: {netcdf_path}\")\n",
    "        \n",
    "        # Read the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "        \n",
    "        # Convert xarray dataset to pandas DataFrame\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        \n",
    "        # Check for 'level' or 'pressure_level' and standardize the column name to 'level'\n",
    "        if 'pressure_level' in df.columns:\n",
    "            df.rename(columns={'pressure_level': 'level'}, inplace=True)\n",
    "            tqdm.write(f\"Renamed 'pressure_level' to 'level' for file: {netcdf_path}\")\n",
    "        elif 'level' not in df.columns:\n",
    "            # If neither column exists, handle surface or raise an error\n",
    "            if 'surface' in os.path.normpath(netcdf_path).split(os.sep):\n",
    "                df['level'] = 1013.0  # Add a 'level' column for surface files\n",
    "                tqdm.write(f\"Added 'level' column with value 1013.0 for surface file: {netcdf_path}\")\n",
    "            else:\n",
    "                raise ValueError(\"'level' column is missing in the pressure file\")\n",
    "        \n",
    "        # Verify all levels are present for pressure files\n",
    "        expected_levels = [1000, 925, 850, 700, 500, 300, 200, 100, 50, 10]\n",
    "        if 'level' in df.columns:\n",
    "            missing_levels = set(expected_levels) - set(df['level'].unique())\n",
    "            if missing_levels:\n",
    "                tqdm.write(f\"Warning: Missing levels in {netcdf_path}: {missing_levels}\")\n",
    "        \n",
    "        # Dynamically handle 'time' or 'valid_time'\n",
    "        time_column = 'time' if 'time' in df.columns else 'valid_time' if 'valid_time' in df.columns else None\n",
    "        if not time_column:\n",
    "            raise ValueError(\"No 'time' or 'valid_time' column found\")\n",
    "        \n",
    "        # Adjust the country name for output folder\n",
    "        relative_path = os.path.relpath(netcdf_path, root_dir)\n",
    "        parts = relative_path.split(os.sep)\n",
    "        if len(parts) >= 2:\n",
    "            parts[1] = adjust_country_name(parts[1])  # Adjust country name if needed\n",
    "        adjusted_relative_path = os.path.join(*parts)\n",
    "        \n",
    "        # Adjust the filename explicitly for Saudi Arabia and United Arab Emirates\n",
    "        country_name = os.path.basename(os.path.dirname(netcdf_path)).strip()\n",
    "        original_filename = os.path.basename(netcdf_path).replace('.nc', '')\n",
    "        if \"Saudi Arabia\" in original_filename:\n",
    "            parquet_file = original_filename.replace(\"Saudi Arabia\", \"Saudi_Arabia\") + '.parquet'\n",
    "        elif \"United Arab Emirates\" in original_filename:\n",
    "            parquet_file = original_filename.replace(\"United Arab Emirates\", \"United_Arab_Emirates\") + '.parquet'\n",
    "        else:\n",
    "            parquet_file = original_filename + '.parquet'\n",
    "        \n",
    "        # Define the output directory and file path\n",
    "        output_dir = os.path.join(output_root_dir, os.path.dirname(adjusted_relative_path))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        parquet_path = os.path.join(output_dir, parquet_file)\n",
    "        \n",
    "        # Write the DataFrame to a Parquet file\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        tqdm.write(f\"Successfully converted {netcdf_path} to {parquet_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Add the file and error to the skipped files list\n",
    "        skipped_files.append((netcdf_path, str(e)))\n",
    "        tqdm.write(f\"Error processing {netcdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Print the summary of skipped files\n",
    "if skipped_files:\n",
    "    print(\"\\nSummary of Skipped Files:\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\"{file}: {error}\")\n",
    "\n",
    "    # Optionally save the skipped files to a CSV for further investigation\n",
    "    skipped_df = pd.DataFrame(skipped_files, columns=[\"File Path\", \"Error Message\"])\n",
    "    skipped_df.to_csv(os.path.join(output_root_dir, \"skipped_files.csv\"), index=False)\n",
    "    print(f\"Skipped files list saved to {os.path.join(output_root_dir, 'skipped_files.csv')}\")\n",
    "else:\n",
    "    print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa138a7-47bc-4708-b3e6-0b647791ba94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
