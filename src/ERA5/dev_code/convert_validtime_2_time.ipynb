{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f78258-f538-494b-8326-246d0a6e1178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1999\\Saudi_Arabia\\pressure\\1999_Saudi_Arabia_pressure_geopotential.parquet\n",
      "\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory and the range of years\n",
    "base_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "years = range(2000, 2001)  # 1989 to 2000 inclusive\n",
    "\n",
    "# Define the countries dictionary\n",
    "countries_dict = {\n",
    "    \"SA\": \"Saudi_Arabia\",\n",
    "    #\"YE\": \"Yemen\",\n",
    "    #\"OM\": \"Oman\",\n",
    "    #\"QA\": \"Qatar\",\n",
    "    #\"BH\": \"Bahrain\",\n",
    "    #\"AE\": \"United_Arab_Emirates\",\n",
    "    #\"KW\": \"Kuwait\"\n",
    "}\n",
    "\n",
    "# Define subdirectories to iterate through\n",
    "folders = [#\"surface\", \n",
    "    \"pressure\"\n",
    "]\n",
    "\n",
    "# Create a list to keep track of files that were skipped due to errors\n",
    "skipped_files = []\n",
    "\n",
    "# Define an output directory for the CSV summary (you can change this as needed)\n",
    "output_root_dir = base_dir  # For example, using base_dir here\n",
    "\n",
    "# Iterate over years, countries, and folders\n",
    "for year in years:\n",
    "    for code, country in countries_dict.items():\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(base_dir, str(year), country, folder)\n",
    "            \n",
    "            # Check if the folder exists\n",
    "            if os.path.exists(folder_path):\n",
    "                for file in os.listdir(folder_path):\n",
    "                    # Process only parquet files\n",
    "                    if file.endswith(\".parquet\"):\n",
    "                        file_path = os.path.join(folder_path, file)\n",
    "                        \n",
    "                        try:\n",
    "                            # Load the parquet file\n",
    "                            df = pd.read_parquet(file_path)\n",
    "                            \n",
    "                            # Check if 'valid_time' column exists and rename it to 'time'\n",
    "                            if 'valid_time' in df.columns:\n",
    "                                df.rename(columns={'valid_time': 'time'}, inplace=True)\n",
    "                                \n",
    "                                # Save the updated dataframe back to the parquet file\n",
    "                                df.to_parquet(file_path, index=False)\n",
    "                                print(f\"Updated column in file: {file_path}\")\n",
    "                        except Exception as e:\n",
    "                            # Print error message and log the file as skipped\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "                            skipped_files.append((file_path, str(e)))\n",
    "            else:\n",
    "                print(f\"Folder does not exist: {folder_path}\")\n",
    "\n",
    "# After processing, check and report any skipped files\n",
    "if skipped_files:\n",
    "    print(\"\\nSummary of Skipped Files:\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\"{file}: {error}\")\n",
    "\n",
    "    # Optionally, save the skipped files information to a CSV for further investigation\n",
    "    skipped_df = pd.DataFrame(skipped_files, columns=[\"File Path\", \"Error Message\"])\n",
    "    csv_path = os.path.join(output_root_dir, \"skipped_files.csv\")\n",
    "    skipped_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Skipped files list saved to {csv_path}\")\n",
    "else:\n",
    "    print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d5073-900e-4fea-8b49-545283e6106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to different output folder ** do this first**\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory and the range of years\n",
    "base_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "output_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\column_change_test\"  # Output directory for modified files\n",
    "years = range(2019, 2020)  # 2019 to 2023 inclusive\n",
    "\n",
    "# Define the countries dictionary\n",
    "countries_dict = {\n",
    "    \"SA\": \"Saudi Arabia\",\n",
    "    \"YE\": \"Yemen\",\n",
    "    \"OM\": \"Oman\",\n",
    "    \"QA\": \"Qatar\",\n",
    "    \"BH\": \"Bahrain\",\n",
    "    \"AE\": \"United Arab Emirates\",\n",
    "    \"KW\": \"Kuwait\"\n",
    "}\n",
    "\n",
    "# Define subdirectories to iterate through\n",
    "folders = [\"surface\", \"pressure\"]\n",
    "\n",
    "# Iterate over years, countries, and folders\n",
    "for year in years:\n",
    "    for code, country in countries_dict.items():\n",
    "        for folder in folders:\n",
    "            input_folder_path = os.path.join(base_dir, str(year), country, folder)\n",
    "            output_folder_path = os.path.join(output_dir, str(year), country, folder)\n",
    "\n",
    "            # Check if the input folder exists\n",
    "            if os.path.exists(input_folder_path):\n",
    "                os.makedirs(output_folder_path, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "                for file in os.listdir(input_folder_path):\n",
    "                    # Check if the file is a parquet file\n",
    "                    if file.endswith(\".parquet\"):\n",
    "                        input_file_path = os.path.join(input_folder_path, file)\n",
    "                        output_file_path = os.path.join(output_folder_path, file)\n",
    "\n",
    "                        try:\n",
    "                            # Load the parquet file\n",
    "                            df = pd.read_parquet(input_file_path)\n",
    "\n",
    "                            # Check if 'valid_time' column exists and rename it\n",
    "                            if 'valid_time' in df.columns:\n",
    "                                df.rename(columns={'valid_time': 'time'}, inplace=True)\n",
    "                                print(f\"Renaming 'valid_time' to 'time' in file: {input_file_path}\")\n",
    "                            \n",
    "                            # Save the modified DataFrame to the output directory\n",
    "                            df.to_parquet(output_file_path, index=False)\n",
    "                            print(f\"Saved updated file to: {output_file_path}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing file {input_file_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Input folder does not exist: {input_folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095bc33-3da7-4798-8b60-8b02d1886731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_10m_u_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_10m_v_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_2m_dewpoint_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_2m_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_convective_available_potential_energy.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_evaporation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_geopotential.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_instantaneous_10m_wind_gust.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_k_index.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_leaf_area_index_high_vegetation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_leaf_area_index_low_vegetation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_mean_sea_level_pressure.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_potential_evaporation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_sea_surface_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_soil_temperature_level_1.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_soil_temperature_level_2.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_soil_temperature_level_3.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_soil_temperature_level_4.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_surface_pressure.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_surface_solar_radiation_downwards.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_surface_thermal_radiation_downwards.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_total_precipitation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_volumetric_soil_water_layer_1.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_volumetric_soil_water_layer_2.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_volumetric_soil_water_layer_3.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\surface\\1989_Saudi_Arabia_surface_volumetric_soil_water_layer_4.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_geopotential.parquet\n",
      "Error processing file Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_relative_humidity.parquet: Unable to allocate 1.18 GiB for an array with shape (1, 158236000) and data type object\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_u_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_vertical_velocity.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_vorticity.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Saudi_Arabia\\pressure\\1989_Saudi_Arabia_pressure_v_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_10m_u_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_10m_v_component_of_wind.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_2m_dewpoint_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_2m_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_convective_available_potential_energy.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_evaporation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_geopotential.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_instantaneous_10m_wind_gust.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_k_index.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_leaf_area_index_high_vegetation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_leaf_area_index_low_vegetation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_mean_sea_level_pressure.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_potential_evaporation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_sea_surface_temperature.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_soil_temperature_level_1.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_soil_temperature_level_2.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_soil_temperature_level_3.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_soil_temperature_level_4.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_surface_pressure.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_surface_solar_radiation_downwards.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_surface_thermal_radiation_downwards.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_total_precipitation.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_volumetric_soil_water_layer_1.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_volumetric_soil_water_layer_2.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_volumetric_soil_water_layer_3.parquet\n",
      "Updated column in file: Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\\1989\\Yemen\\surface\\1989_Yemen_surface_volumetric_soil_water_layer_4.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory and the range of years\n",
    "base_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "years = range(1989, 2001)  # 2019 to 2023 inclusive\n",
    "\n",
    "# Define the countries dictionary\n",
    "countries_dict = {\n",
    "    \"SA\": \"Saudi_Arabia\",\n",
    "    \"YE\": \"Yemen\",\n",
    "    \"OM\": \"Oman\",\n",
    "    \"QA\": \"Qatar\",\n",
    "    \"BH\": \"Bahrain\",\n",
    "    \"AE\": \"United_Arab_Emirates\",\n",
    "    \"KW\": \"Kuwait\"\n",
    "}\n",
    "\n",
    "# Define subdirectories to iterate through\n",
    "folders = [\"surface\",\n",
    "           \"pressure\"\n",
    "          ]\n",
    "\n",
    "# Iterate over years, countries, and folders\n",
    "for year in years:\n",
    "    for code, country in countries_dict.items():\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(base_dir, str(year), country, folder)\n",
    "            \n",
    "            # Check if the folder exists\n",
    "            if os.path.exists(folder_path):\n",
    "                for file in os.listdir(folder_path):\n",
    "                    # Check if the file is a parquet file\n",
    "                    if file.endswith(\".parquet\"):\n",
    "                        file_path = os.path.join(folder_path, file)\n",
    "                        \n",
    "                        try:\n",
    "                            # Load the parquet file\n",
    "                            df = pd.read_parquet(file_path)\n",
    "                            \n",
    "                            # Check if 'valid_time' column exists and rename it\n",
    "                            if 'valid_time' in df.columns:\n",
    "                                df.rename(columns={'valid_time': 'time'}, inplace=True)\n",
    "                                \n",
    "                                # Save the updated dataframe back to the parquet file\n",
    "                                df.to_parquet(file_path, index=False)\n",
    "                                print(f\"Updated column in file: {file_path}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Folder does not exist: {folder_path}\")\n",
    "            # Print the summary of skipped files\n",
    "if skipped_files:\n",
    "    print(\"\\nSummary of Skipped Files:\")\n",
    "    for file, error in skipped_files:\n",
    "        print(f\"{file}: {error}\")\n",
    "\n",
    "    # Optionally save the skipped files to a CSV for further investigation\n",
    "    skipped_df = pd.DataFrame(skipped_files, columns=[\"File Path\", \"Error Message\"])\n",
    "    skipped_df.to_csv(os.path.join(output_root_dir, \"skipped_files.csv\"), index=False)\n",
    "    print(f\"Skipped files list saved to {os.path.join(output_root_dir, 'skipped_files.csv')}\")\n",
    "else:\n",
    "    print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a3997-48e7-4bc1-9c04-ce0841118f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above was previously operational, I think the memory was overloaded When processing^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4ffd4-4a04-4fba-a882-eea4445ac751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyarrow.parquet import ParquetFile\n",
    "\n",
    "# Define the base directory and the range of years\n",
    "base_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "years = range(1985, 1986)  # Adjust year range as needed\n",
    "\n",
    "# Define the countries dictionary\n",
    "countries_dict = {\n",
    "    \"SA\": \"Saudi_Arabia\",\n",
    "    # Uncomment other countries as needed\n",
    "    # \"YE\": \"Yemen\",\n",
    "    # \"OM\": \"Oman\",\n",
    "    # \"QA\": \"Qatar\",\n",
    "    # \"BH\": \"Bahrain\",\n",
    "    # \"AE\": \"United_Arab_Emirates\",\n",
    "    # \"KW\": \"Kuwait\"\n",
    "}\n",
    "\n",
    "# Define subdirectories to iterate through\n",
    "folders = [\"pressure\"]  # Add \"surface\" if needed\n",
    "\n",
    "# Function to process parquet file in chunks\n",
    "def process_parquet_in_chunks(file_path, output_path, chunk_size=1000):\n",
    "    try:\n",
    "        # Open parquet file using pyarrow\n",
    "        parquet_file = ParquetFile(file_path)\n",
    "        \n",
    "        # Write to a new parquet file in chunks\n",
    "        writer = None\n",
    "        for i, batch in enumerate(parquet_file.iter_batches(batch_size=chunk_size)):\n",
    "            # Convert batch to pandas DataFrame\n",
    "            df = batch.to_pandas()\n",
    "            \n",
    "            # Rename 'valid_time' column if it exists\n",
    "            if 'valid_time' in df.columns:\n",
    "                df.rename(columns={'valid_time': 'time'}, inplace=True)\n",
    "            \n",
    "            # Append to the output file\n",
    "            if writer is None:\n",
    "                writer = pd.DataFrame(df).to_parquet(output_path, index=False, engine=\"pyarrow\")\n",
    "            else:\n",
    "                df.to_parquet(output_path, index=False, engine=\"pyarrow\", append=True)\n",
    "        \n",
    "        if writer:\n",
    "            print(f\"Successfully processed and saved: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Iterate over years, countries, and folders\n",
    "for year in years:\n",
    "    for code, country in countries_dict.items():\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(base_dir, str(year), country, folder)\n",
    "            \n",
    "            # Check if the folder exists\n",
    "            if os.path.exists(folder_path):\n",
    "                for file in os.listdir(folder_path):\n",
    "                    if file.endswith(\".parquet\"):\n",
    "                        file_path = os.path.join(folder_path, file)\n",
    "                        output_file_path = file_path.replace(\".parquet\", \"_processed.parquet\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Process and save the parquet file in chunks\n",
    "                            process_parquet_in_chunks(file_path, output_file_path)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Folder does not exist: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c1855-35d7-42cc-9b5a-c95d281b424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyarrow.parquet import ParquetFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the base directory and the range of years\n",
    "base_dir = r\"Z:\\Thesis\\Data\\Met\\ERA5_parquet_test\"\n",
    "years = range(1986, 1988)  # Adjust year range as needed\n",
    "\n",
    "# Define the countries dictionary\n",
    "countries_dict = {\n",
    "    \"SA\": \"Saudi_Arabia\",\n",
    "    # Uncomment other countries as needed\n",
    "    \"YE\": \"Yemen\",\n",
    "    \"OM\": \"Oman\",\n",
    "    \"QA\": \"Qatar\",\n",
    "    \"BH\": \"Bahrain\",\n",
    "    \"AE\": \"United_Arab_Emirates\",\n",
    "    \"KW\": \"Kuwait\"\n",
    "}\n",
    "\n",
    "# Define subdirectories to iterate through\n",
    "folders = [\"pressure\"]  # Add \"surface\" if needed\n",
    "\n",
    "# Function to process parquet file in chunks\n",
    "def process_parquet_in_chunks(file_path, output_path, chunk_size=100_000):\n",
    "    try:\n",
    "        # Open parquet file using pyarrow\n",
    "        parquet_file = ParquetFile(file_path)\n",
    "        total_batches = parquet_file.metadata.num_rows // chunk_size + 1\n",
    "        writer = None\n",
    "\n",
    "        # Iterate over batches with progress tracking\n",
    "        for i, batch in enumerate(tqdm(parquet_file.iter_batches(batch_size=chunk_size), \n",
    "                                       desc=f\"Processing {os.path.basename(file_path)}\", \n",
    "                                       total=total_batches)):\n",
    "            # Convert batch to pandas DataFrame\n",
    "            df = batch.to_pandas()\n",
    "            \n",
    "            # Rename 'valid_time' column if it exists\n",
    "            if 'valid_time' in df.columns:\n",
    "                df.rename(columns={'valid_time': 'time'}, inplace=True)\n",
    "            \n",
    "            # Write to the output file (overwrite for the first chunk, then append)\n",
    "            if writer is None:\n",
    "                df.to_parquet(output_path, index=False, engine=\"pyarrow\")\n",
    "                writer = True  # Initialize writer after the first write\n",
    "            else:\n",
    "                df.to_parquet(output_path, index=False, engine=\"pyarrow\", append=True)\n",
    "        \n",
    "        print(f\"Successfully processed and saved: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Iterate over years, countries, and folders\n",
    "for year in tqdm(years, desc=\"Processing Years\"):\n",
    "    for code, country in tqdm(countries_dict.items(), desc=\"Processing Countries\"):\n",
    "        for folder in tqdm(folders, desc=\"Processing Folders\"):\n",
    "            folder_path = os.path.join(base_dir, str(year), country, folder)\n",
    "            \n",
    "            # Check if the folder exists\n",
    "            if os.path.exists(folder_path):\n",
    "                files = [f for f in os.listdir(folder_path) if f.endswith(\".parquet\")]\n",
    "                for file in tqdm(files, desc=f\"Processing Files in {folder_path}\"):\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    output_file_path = file_path.replace(\".parquet\", \"_processed.parquet\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Process and save the parquet file in chunks\n",
    "                        process_parquet_in_chunks(file_path, output_file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing file {file_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Folder does not exist: {folder_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
