{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83581b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Bahrain] After concatenation: train_df.shape = (1116, 106)\n",
      "DEBUG: [Bahrain] After dropping columns: train_df.shape = (1116, 88)\n",
      "DEBUG: [Bahrain] After sorting: train_df.shape = (1116, 88)\n",
      "DEBUG: [Bahrain] After creating 'lag_1': train_df.shape = (1116, 89)\n",
      "DEBUG: [Bahrain] After dropping NaNs for target and lag_1: train_df.shape = (1110, 89)\n",
      "DEBUG: [Bahrain] X_train_full.shape = (1110, 87), y_train_full.shape = (1110,)\n",
      "DEBUG: [Bahrain] Split -> X_train_part=(777, 87), X_val_part=(333, 87)\n",
      "DEBUG: [Bahrain] Finished training models.\n",
      "DEBUG: [Bahrain] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Bahrain] Loaded test_df_2023: shape = (36, 106)\n",
      "DEBUG: [Bahrain] After dropping columns in test_df_2023: (36, 88)\n",
      "DEBUG: [Bahrain] After sorting test_df_2023: shape=(36, 89)\n",
      "DEBUG: [Bahrain] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Bahrain] Month=2023-01, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] Merging with dec_2022: dec_2022.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Jan 2023): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-02, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-02): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-03, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-03): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-04, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-04): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-05, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-05): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-06, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-06): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-07, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-07): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-08, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-08): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-09, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-09): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-10, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-10): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-11, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-11): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] Month=2023-12, initial this_month_df.shape = (3, 89)\n",
      "DEBUG: [Bahrain] prev_month_data.shape = (3, 4)\n",
      "DEBUG: [Bahrain] After merge (Month=2023-12): this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] After dropping NA lag_1: this_month_df.shape = (3, 90)\n",
      "DEBUG: [Bahrain] X_this_month.shape before reindex = (3, 87)\n",
      "DEBUG: [Bahrain] X_this_month.shape after reindex = (3, 87)\n",
      "DEBUG: [Bahrain] test_df_2023_preds.shape (after concat months) = (36, 95)\n",
      "DEBUG: [Yemen] After concatenation: train_df.shape = (529728, 106)\n",
      "DEBUG: [Yemen] After dropping columns: train_df.shape = (529728, 88)\n",
      "DEBUG: [Yemen] After sorting: train_df.shape = (529728, 88)\n",
      "DEBUG: [Yemen] After creating 'lag_1': train_df.shape = (529728, 89)\n",
      "DEBUG: [Yemen] After dropping NaNs for target and lag_1: train_df.shape = (526880, 89)\n",
      "DEBUG: [Yemen] X_train_full.shape = (526880, 87), y_train_full.shape = (526880,)\n",
      "DEBUG: [Yemen] Split -> X_train_part=(368816, 87), X_val_part=(158064, 87)\n",
      "DEBUG: [Yemen] Finished training models.\n",
      "DEBUG: [Yemen] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Yemen] Loaded test_df_2023: shape = (17088, 106)\n",
      "DEBUG: [Yemen] After dropping columns in test_df_2023: (17088, 88)\n",
      "DEBUG: [Yemen] After sorting test_df_2023: shape=(17088, 89)\n",
      "DEBUG: [Yemen] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Yemen] Month=2023-01, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] Merging with dec_2022: dec_2022.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Jan 2023): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-02, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-02): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-03, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-03): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-04, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-04): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Yemen] Month=2023-05, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-05): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-06, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-06): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-07, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-07): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-08, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-08): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-09, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-09): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-10, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-10): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-11, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-11): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] Month=2023-12, initial this_month_df.shape = (1424, 89)\n",
      "DEBUG: [Yemen] prev_month_data.shape = (1424, 4)\n",
      "DEBUG: [Yemen] After merge (Month=2023-12): this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] After dropping NA lag_1: this_month_df.shape = (1424, 90)\n",
      "DEBUG: [Yemen] X_this_month.shape before reindex = (1424, 87)\n",
      "DEBUG: [Yemen] X_this_month.shape after reindex = (1424, 87)\n",
      "DEBUG: [Yemen] test_df_2023_preds.shape (after concat months) = (17088, 95)\n",
      "DEBUG: [Kuwait] After concatenation: train_df.shape = (20832, 106)\n",
      "DEBUG: [Kuwait] After dropping columns: train_df.shape = (20832, 88)\n",
      "DEBUG: [Kuwait] After sorting: train_df.shape = (20832, 88)\n",
      "DEBUG: [Kuwait] After creating 'lag_1': train_df.shape = (20832, 89)\n",
      "DEBUG: [Kuwait] After dropping NaNs for target and lag_1: train_df.shape = (20720, 89)\n",
      "DEBUG: [Kuwait] X_train_full.shape = (20720, 87), y_train_full.shape = (20720,)\n",
      "DEBUG: [Kuwait] Split -> X_train_part=(14504, 87), X_val_part=(6216, 87)\n",
      "DEBUG: [Kuwait] Finished training models.\n",
      "DEBUG: [Kuwait] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Kuwait] Loaded test_df_2023: shape = (672, 106)\n",
      "DEBUG: [Kuwait] After dropping columns in test_df_2023: (672, 88)\n",
      "DEBUG: [Kuwait] After sorting test_df_2023: shape=(672, 89)\n",
      "DEBUG: [Kuwait] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Kuwait] Month=2023-01, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] Merging with dec_2022: dec_2022.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Jan 2023): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-02, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-02): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-03, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-03): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-04, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-04): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-05, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-05): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-06, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-06): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-07, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-07): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-08, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-08): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-09, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-09): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-10, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-10): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Kuwait] Month=2023-11, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-11): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] Month=2023-12, initial this_month_df.shape = (56, 89)\n",
      "DEBUG: [Kuwait] prev_month_data.shape = (56, 4)\n",
      "DEBUG: [Kuwait] After merge (Month=2023-12): this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] After dropping NA lag_1: this_month_df.shape = (56, 90)\n",
      "DEBUG: [Kuwait] X_this_month.shape before reindex = (56, 87)\n",
      "DEBUG: [Kuwait] X_this_month.shape after reindex = (56, 87)\n",
      "DEBUG: [Kuwait] test_df_2023_preds.shape (after concat months) = (672, 95)\n",
      "DEBUG: [Oman] After concatenation: train_df.shape = (476160, 106)\n",
      "DEBUG: [Oman] After dropping columns: train_df.shape = (476160, 88)\n",
      "DEBUG: [Oman] After sorting: train_df.shape = (476160, 88)\n",
      "DEBUG: [Oman] After creating 'lag_1': train_df.shape = (476160, 89)\n",
      "DEBUG: [Oman] After dropping NaNs for target and lag_1: train_df.shape = (473600, 89)\n",
      "DEBUG: [Oman] X_train_full.shape = (473600, 87), y_train_full.shape = (473600,)\n",
      "DEBUG: [Oman] Split -> X_train_part=(331520, 87), X_val_part=(142080, 87)\n",
      "DEBUG: [Oman] Finished training models.\n",
      "DEBUG: [Oman] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Oman] Loaded test_df_2023: shape = (15360, 106)\n",
      "DEBUG: [Oman] After dropping columns in test_df_2023: (15360, 88)\n",
      "DEBUG: [Oman] After sorting test_df_2023: shape=(15360, 89)\n",
      "DEBUG: [Oman] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Oman] Month=2023-01, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] Merging with dec_2022: dec_2022.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Jan 2023): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-02, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-02): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-03, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-03): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-04, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-04): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-05, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-05): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-06, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-06): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-07, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-07): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-08, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-08): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-09, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-09): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-10, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-10): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-11, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-11): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] Month=2023-12, initial this_month_df.shape = (1280, 89)\n",
      "DEBUG: [Oman] prev_month_data.shape = (1280, 4)\n",
      "DEBUG: [Oman] After merge (Month=2023-12): this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] After dropping NA lag_1: this_month_df.shape = (1280, 90)\n",
      "DEBUG: [Oman] X_this_month.shape before reindex = (1280, 87)\n",
      "DEBUG: [Oman] X_this_month.shape after reindex = (1280, 87)\n",
      "DEBUG: [Oman] test_df_2023_preds.shape (after concat months) = (15360, 95)\n",
      "DEBUG: [Qatar] After concatenation: train_df.shape = (10416, 106)\n",
      "DEBUG: [Qatar] After dropping columns: train_df.shape = (10416, 88)\n",
      "DEBUG: [Qatar] After sorting: train_df.shape = (10416, 88)\n",
      "DEBUG: [Qatar] After creating 'lag_1': train_df.shape = (10416, 89)\n",
      "DEBUG: [Qatar] After dropping NaNs for target and lag_1: train_df.shape = (10360, 89)\n",
      "DEBUG: [Qatar] X_train_full.shape = (10360, 87), y_train_full.shape = (10360,)\n",
      "DEBUG: [Qatar] Split -> X_train_part=(7252, 87), X_val_part=(3108, 87)\n",
      "DEBUG: [Qatar] Finished training models.\n",
      "DEBUG: [Qatar] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Qatar] Loaded test_df_2023: shape = (336, 106)\n",
      "DEBUG: [Qatar] After dropping columns in test_df_2023: (336, 88)\n",
      "DEBUG: [Qatar] After sorting test_df_2023: shape=(336, 89)\n",
      "DEBUG: [Qatar] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Qatar] Month=2023-01, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] Merging with dec_2022: dec_2022.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Jan 2023): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Qatar] Month=2023-02, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-02): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-03, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-03): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-04, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-04): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-05, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-05): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-06, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-06): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-07, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-07): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-08, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-08): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-09, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-09): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-10, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-10): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-11, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-11): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] Month=2023-12, initial this_month_df.shape = (28, 89)\n",
      "DEBUG: [Qatar] prev_month_data.shape = (28, 4)\n",
      "DEBUG: [Qatar] After merge (Month=2023-12): this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] After dropping NA lag_1: this_month_df.shape = (28, 90)\n",
      "DEBUG: [Qatar] X_this_month.shape before reindex = (28, 87)\n",
      "DEBUG: [Qatar] X_this_month.shape after reindex = (28, 87)\n",
      "DEBUG: [Qatar] test_df_2023_preds.shape (after concat months) = (336, 95)\n",
      "DEBUG: [Saudi_Arabia] After concatenation: train_df.shape = (2055300, 106)\n",
      "DEBUG: [Saudi_Arabia] After dropping columns: train_df.shape = (2055300, 88)\n",
      "DEBUG: [Saudi_Arabia] After sorting: train_df.shape = (2055300, 88)\n",
      "DEBUG: [Saudi_Arabia] After creating 'lag_1': train_df.shape = (2055300, 89)\n",
      "DEBUG: [Saudi_Arabia] After dropping NaNs for target and lag_1: train_df.shape = (2049775, 89)\n",
      "DEBUG: [Saudi_Arabia] X_train_full.shape = (2049775, 87), y_train_full.shape = (2049775,)\n",
      "DEBUG: [Saudi_Arabia] Split -> X_train_part=(1434842, 87), X_val_part=(614933, 87)\n",
      "DEBUG: [Saudi_Arabia] Finished training models.\n",
      "DEBUG: [Saudi_Arabia] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [Saudi_Arabia] Loaded test_df_2023: shape = (66300, 106)\n",
      "DEBUG: [Saudi_Arabia] After dropping columns in test_df_2023: (66300, 88)\n",
      "DEBUG: [Saudi_Arabia] After sorting test_df_2023: shape=(66300, 89)\n",
      "DEBUG: [Saudi_Arabia] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [Saudi_Arabia] Month=2023-01, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] Merging with dec_2022: dec_2022.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Jan 2023): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-02, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-02): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-03, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-03): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-04, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-04): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-05, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-05): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-06, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-06): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-07, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-07): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Saudi_Arabia] Month=2023-08, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-08): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-09, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-09): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-10, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-10): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-11, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-11): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] Month=2023-12, initial this_month_df.shape = (5525, 89)\n",
      "DEBUG: [Saudi_Arabia] prev_month_data.shape = (5525, 4)\n",
      "DEBUG: [Saudi_Arabia] After merge (Month=2023-12): this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] After dropping NA lag_1: this_month_df.shape = (5525, 90)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape before reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] X_this_month.shape after reindex = (5525, 87)\n",
      "DEBUG: [Saudi_Arabia] test_df_2023_preds.shape (after concat months) = (66300, 95)\n",
      "DEBUG: [United_Arab_Emirates] After concatenation: train_df.shape = (104160, 106)\n",
      "DEBUG: [United_Arab_Emirates] After dropping columns: train_df.shape = (104160, 88)\n",
      "DEBUG: [United_Arab_Emirates] After sorting: train_df.shape = (104160, 88)\n",
      "DEBUG: [United_Arab_Emirates] After creating 'lag_1': train_df.shape = (104160, 89)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NaNs for target and lag_1: train_df.shape = (103600, 89)\n",
      "DEBUG: [United_Arab_Emirates] X_train_full.shape = (103600, 87), y_train_full.shape = (103600,)\n",
      "DEBUG: [United_Arab_Emirates] Split -> X_train_part=(72520, 87), X_val_part=(31080, 87)\n",
      "DEBUG: [United_Arab_Emirates] Finished training models.\n",
      "DEBUG: [United_Arab_Emirates] Skipping decision boundary plot (requires 2 features).\n",
      "DEBUG: [United_Arab_Emirates] Loaded test_df_2023: shape = (3360, 106)\n",
      "DEBUG: [United_Arab_Emirates] After dropping columns in test_df_2023: (3360, 88)\n",
      "DEBUG: [United_Arab_Emirates] After sorting test_df_2023: shape=(3360, 89)\n",
      "DEBUG: [United_Arab_Emirates] unique_months_2023 = [Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M'), Period('2023-04', 'M'), Period('2023-05', 'M'), Period('2023-06', 'M'), Period('2023-07', 'M'), Period('2023-08', 'M'), Period('2023-09', 'M'), Period('2023-10', 'M'), Period('2023-11', 'M'), Period('2023-12', 'M')]\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-01, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] Merging with dec_2022: dec_2022.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Jan 2023): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-02, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-02): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-03, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-03): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-04, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-04): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-05, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-05): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-06, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-06): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-07, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-07): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-08, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-08): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-09, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-09): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-10, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-10): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [United_Arab_Emirates] Month=2023-11, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-11): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] Month=2023-12, initial this_month_df.shape = (280, 89)\n",
      "DEBUG: [United_Arab_Emirates] prev_month_data.shape = (280, 4)\n",
      "DEBUG: [United_Arab_Emirates] After merge (Month=2023-12): this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] After dropping NA lag_1: this_month_df.shape = (280, 90)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape before reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] X_this_month.shape after reindex = (280, 87)\n",
      "DEBUG: [United_Arab_Emirates] test_df_2023_preds.shape (after concat months) = (3360, 95)\n",
      "Main loop complete! Saving Results...\n",
      "Feature importances saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_feature_importances_2023_v0063.csv'\n",
      "DEBUG: [ALL] full_predictions_2023.shape = (103152, 96)\n",
      "Row-level predictions for 2023 (ensemble + individual models) saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_row_level_predictions_2023_v0063.csv'\n",
      "DEBUG: [ALL] monthly_ensemble_df_2023.shape = (103152, 6)\n",
      "Monthly ensemble predictions for 2023 saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_monthly_ensemble_predictions_2023_v0063.csv'\n",
      "DEBUG: [ALL] lr monthly dataframe shape = (103152, 6)\n",
      "Monthly predictions for 2023 for model 'lr' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_monthly_predictions_2023_lr_v0063.csv'\n",
      "DEBUG: [ALL] knn monthly dataframe shape = (103152, 6)\n",
      "Monthly predictions for 2023 for model 'knn' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_monthly_predictions_2023_knn_v0063.csv'\n",
      "DEBUG: [ALL] dt monthly dataframe shape = (103152, 6)\n",
      "Monthly predictions for 2023 for model 'dt' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_monthly_predictions_2023_dt_v0063.csv'\n",
      "DEBUG: [ALL] rf monthly dataframe shape = (103152, 6)\n",
      "Monthly predictions for 2023 for model 'rf' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_monthly_predictions_2023_rf_v0063.csv'\n",
      "Model metrics (including Ensemble) saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\\sfc_model_metrics_2023_v0063.csv'\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Welcome to DustCast V0.0.6.3 SFC! \n",
    "# This version trains on 1980-2000 and 2013-2022 Surface data and predicts DUSMASS_mean for the year 2023 by month. \n",
    "# A one-month lag is integrated so that each 2023 prediction uses the previous months value.\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    \"\"\"Helper function to compute Mean Squared Error.\"\"\"\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def train_models(regressors, X_train, y_train):\n",
    "    \"\"\"Train each regressor on the training data and return the trained models.\"\"\"\n",
    "    models = []\n",
    "    for name, model in regressors:\n",
    "        model.fit(X_train, y_train)\n",
    "        models.append((name, model))\n",
    "    return models\n",
    "\n",
    "def compute_metrics_and_weights(models, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Compute each model's MSE, MAE, R^2, and weight = 1/(MSE + 1e-20).\n",
    "\n",
    "    Returns: (model_names, mse_list, mae_list, r2_list, weights)\n",
    "    \"\"\"\n",
    "    model_names = []\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    r2_list = []\n",
    "    weights = []\n",
    "\n",
    "    for name, model in models:\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        curr_mse = mse(y_val, y_pred_val)\n",
    "        mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "        r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "        # Compute weight as inverse of MSE\n",
    "        w = 1 / (curr_mse + 1e-20)\n",
    "\n",
    "        model_names.append(name)\n",
    "        mse_list.append(curr_mse)\n",
    "        mae_list.append(mae_val)\n",
    "        r2_list.append(r2_val)\n",
    "        weights.append(w)\n",
    "\n",
    "    # Normalize weights (so they sum to 1)\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    return model_names, mse_list, mae_list, r2_list, weights\n",
    "\n",
    "def predict_weighted(models, X_val, y_val, X_test):\n",
    "    \"\"\"\n",
    "    Compute weights for each model (inverse of MSE) on (X_val, y_val),\n",
    "    and make weighted ensemble predictions on X_test.\n",
    "\n",
    "    Returns:\n",
    "      final_prediction (ndarray): Weighted ensemble predictions on X_test.\n",
    "      weights (ndarray): The normalized weights for each model.\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    predictions = []\n",
    "\n",
    "    # Compute MSE on validation set -> weights (inverse MSE)\n",
    "    for name, model in models:\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        curr_mse = mse(y_val, y_pred_val)\n",
    "        weights.append(1 / (curr_mse + 1e-20))\n",
    "        predictions.append(model.predict(X_test))\n",
    "\n",
    "    # Normalize weights\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # Weighted average of predictions\n",
    "    predictions = np.array(predictions)  # shape: (num_models, num_samples)\n",
    "    final_prediction = np.dot(weights, predictions)\n",
    "\n",
    "    return final_prediction, weights\n",
    "\n",
    "# ------------------------- CONFIGURATION -------------------------\n",
    "base_path = r\"Z:\\Thesis\\Data\\ML_Data\\AP_ML_training_data\"\n",
    "output_dir = r\"Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\SFC\\\\DC_v0063\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_years = [\n",
    "    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
    "    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
    "    2000,\n",
    "    2013, 2014, 2015, 2016, 2017, 2018, 2019, \n",
    "    2020, 2021, 2022\n",
    "]\n",
    "test_year = 2023\n",
    "\n",
    "countries = [\n",
    "    \"Bahrain\",\n",
    "    \"Yemen\", \n",
    "    \"Kuwait\", \n",
    "    \"Oman\", \n",
    "    \"Qatar\", \n",
    "    \"Saudi_Arabia\", \n",
    "    \"United_Arab_Emirates\"\n",
    "]\n",
    "\n",
    "# Define regressors\n",
    "regressors = [\n",
    "    ('lr', LinearRegression(copy_X=True, fit_intercept=True)),\n",
    "    ('knn', KNeighborsRegressor(algorithm='ball_tree', leaf_size=5,\n",
    "                                n_neighbors=5, p=2, weights='distance')),\n",
    "    ('dt', DecisionTreeRegressor(max_depth=None, max_features=20,\n",
    "                                 min_samples_split=10, random_state=13)),\n",
    "    ('rf', RandomForestRegressor(max_depth=13, n_estimators=50, \n",
    "                                 max_features=20, min_samples_split=10, random_state=23))   \n",
    "]\n",
    "\n",
    "target_column = 'DUSMASS_mean'\n",
    "\n",
    "cols_to_drop = [\n",
    "    'sst_min', 'sst_max', 'sst_mean',\n",
    "    'DUSMASS25_min', 'DUSMASS25_max', 'DUSMASS25_mean',\n",
    "    'DUSMASS_min', 'DUSMASS_max','h3_res_5', 'h3_res_6', \n",
    "    'h3_res_5_int', 'h3_res_6_int', 'h3_res_3', 'h3_res_3_int', \n",
    "    'h3_res_4', 'h3_res_4_int', 'year', 'month'\n",
    "]\n",
    "\n",
    "# ------------------------- OUTPUT STORAGES -------------------------\n",
    "all_feature_importances = []\n",
    "predictions_2023_all_countries = []\n",
    "monthly_ensemble_predictions_2023 = []\n",
    "monthly_model_predictions_2023 = {name: [] for name, _ in regressors}\n",
    "all_model_metrics = []  # Store each country's model metrics (MSE, MAE, R2, Weight), plus ensemble metrics\n",
    "\n",
    "# ------------------------- MAIN LOOP -------------------------\n",
    "for country in countries:\n",
    "    try:\n",
    "        # 1) Load and combine training data\n",
    "        train_frames = []\n",
    "        for yr in train_years:\n",
    "            file_path = os.path.join(base_path, str(yr), f\"{country}_{yr}_surface_monthly_stats_merged.parquet\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Training file not found: {file_path}\")\n",
    "                continue\n",
    "            df_temp = pd.read_parquet(file_path)\n",
    "            train_frames.append(df_temp)\n",
    "        \n",
    "        if len(train_frames) == 0:\n",
    "            print(f\"No training data found for {country}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        train_df = pd.concat(train_frames, ignore_index=True)\n",
    "        print(f\"DEBUG: [{country}] After concatenation: train_df.shape = {train_df.shape}\")\n",
    "\n",
    "        train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "\n",
    "        # Drop columns\n",
    "        train_df.drop(columns=[c for c in cols_to_drop if c in train_df.columns], \n",
    "                      inplace=True, errors='ignore')\n",
    "        print(f\"DEBUG: [{country}] After dropping columns: train_df.shape = {train_df.shape}\")\n",
    "\n",
    "        # Create a 1-month lag of the target\n",
    "        train_df = train_df.sort_values(by=['lat', 'lon', 'time'])\n",
    "        print(f\"DEBUG: [{country}] After sorting: train_df.shape = {train_df.shape}\")\n",
    "        train_df['lag_1'] = train_df.groupby(['lat', 'lon'])[target_column].shift(1)\n",
    "        print(f\"DEBUG: [{country}] After creating 'lag_1': train_df.shape = {train_df.shape}\")\n",
    "\n",
    "        # Drop NaNs for target or lag_1\n",
    "        train_df = train_df.dropna(subset=[target_column, 'lag_1'])\n",
    "        print(f\"DEBUG: [{country}] After dropping NaNs for target and lag_1: train_df.shape = {train_df.shape}\")\n",
    "\n",
    "        # 2) Features / Target\n",
    "        X_train_full = train_df.drop(columns=[target_column, 'time'], errors='ignore')\n",
    "        y_train_full = train_df[target_column]\n",
    "        print(f\"DEBUG: [{country}] X_train_full.shape = {X_train_full.shape}, y_train_full.shape = {y_train_full.shape}\")\n",
    "\n",
    "        # 3) Train-Validation Split\n",
    "        X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(\n",
    "            X_train_full,\n",
    "            y_train_full,\n",
    "            test_size=0.3,\n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"DEBUG: [{country}] Split -> X_train_part={X_train_part.shape}, X_val_part={X_val_part.shape}\")\n",
    "\n",
    "        # Impute\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_part_imp = imputer.fit_transform(X_train_part)\n",
    "        X_val_part_imp   = imputer.transform(X_val_part)\n",
    "\n",
    "        X_train_part = pd.DataFrame(X_train_part_imp, columns=X_train_part.columns, index=X_train_part.index)\n",
    "        X_val_part   = pd.DataFrame(X_val_part_imp,   columns=X_val_part.columns,   index=X_val_part.index)\n",
    "\n",
    "        # 4) Train Models\n",
    "        models = train_models(regressors, X_train_part, y_train_part)\n",
    "        print(f\"DEBUG: [{country}] Finished training models.\")\n",
    "\n",
    "        # Define output directory for decision boundary plots\n",
    "        decision_boundary_dir = os.path.join(output_dir, \"decision_boundaries\")\n",
    "        os.makedirs(decision_boundary_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "        # 4.1) Plot Decision Boundaries (if X_train_part has exactly 2 features)\n",
    "        if X_train_part.shape[1] == 2:\n",
    "            import matplotlib.pyplot as plt  # ensure matplotlib is imported\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "            axes = axes.flatten()\n",
    "    \n",
    "            for i, (name, model) in enumerate(models):\n",
    "                if i >= len(axes):\n",
    "                    break\n",
    "                # Your decision boundary plotting function should be defined elsewhere.\n",
    "                plot_decision_boundary(axes[i], model, X_train_part.to_numpy(), y_train_part.to_numpy(), f\"{country} - {name}\")\n",
    "\n",
    "            # Save decision boundary plots\n",
    "            fig.tight_layout()\n",
    "            decision_boundary_path = os.path.join(decision_boundary_dir, f\"{country}_decision_boundaries.png\")\n",
    "            plt.savefig(decision_boundary_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "            print(f\"DEBUG: [{country}] Decision boundary plots saved to '{decision_boundary_path}'\")\n",
    "        else:\n",
    "            print(f\"DEBUG: [{country}] Skipping decision boundary plot (requires 2 features).\")\n",
    "\n",
    "        # 4.2) Feature Importances\n",
    "        feature_importances = pd.DataFrame(index=X_train_part.columns)\n",
    "        for name, model in models:\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                feature_importances[name] = model.feature_importances_\n",
    "\n",
    "        if not feature_importances.empty:\n",
    "            feature_importances.reset_index(inplace=True)\n",
    "            feature_importances.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "            feature_importances['Country'] = country\n",
    "            all_feature_importances.append(feature_importances)\n",
    "\n",
    "        # 4.3) Compute model-level metrics\n",
    "        model_names, mse_list, mae_list, r2_list, weights_array = compute_metrics_and_weights(models, X_val_part, y_val_part)\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Country': country,\n",
    "            'Model': model_names,\n",
    "            'MSE': mse_list,\n",
    "            'MAE': mae_list,\n",
    "            'R2': r2_list,\n",
    "            'Weight': weights_array\n",
    "        })\n",
    "\n",
    "        # 4.4) Ensemble metrics on validation\n",
    "        ensemble_val_preds, _ = predict_weighted(models, X_val_part, y_val_part, X_val_part)\n",
    "        ensemble_mse_val = mse(y_val_part, ensemble_val_preds)\n",
    "        ensemble_mae_val  = mean_absolute_error(y_val_part, ensemble_val_preds)\n",
    "        ensemble_r2_val   = r2_score(y_val_part, ensemble_val_preds)\n",
    "\n",
    "        ensemble_row = {\n",
    "            'Country': country,\n",
    "            'Model': 'ensemble',\n",
    "            'MSE': ensemble_mse_val,\n",
    "            'MAE': ensemble_mae_val,\n",
    "            'R2': ensemble_r2_val,\n",
    "            'Weight': 1.0\n",
    "        }\n",
    "        ensemble_df = pd.DataFrame([ensemble_row])\n",
    "        metrics_df = pd.concat([metrics_df, ensemble_df], ignore_index=True)\n",
    "\n",
    "        all_model_metrics.append(metrics_df)\n",
    "\n",
    "        # 5) Prepare Test Data for 2023 Month-by-Month\n",
    "        test_file_path = os.path.join(base_path, str(test_year), f\"{country}_{test_year}_surface_monthly_stats_merged.parquet\")\n",
    "        if not os.path.exists(test_file_path):\n",
    "            print(f\"Test file (2023) not found for {country}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        test_df_2023 = pd.read_parquet(test_file_path)\n",
    "        print(f\"DEBUG: [{country}] Loaded test_df_2023: shape = {test_df_2023.shape}\")\n",
    "\n",
    "        test_df_2023['time'] = pd.to_datetime(test_df_2023['time'])\n",
    "        test_df_2023.drop(columns=[c for c in cols_to_drop if c in test_df_2023.columns], inplace=True, errors='ignore')\n",
    "        print(f\"DEBUG: [{country}] After dropping columns in test_df_2023: {test_df_2023.shape}\")\n",
    "\n",
    "        test_df_2023 = test_df_2023.sort_values(by=['lat', 'lon', 'time'])\n",
    "        test_df_2023['Month'] = test_df_2023['time'].dt.to_period('M')\n",
    "        print(f\"DEBUG: [{country}] After sorting test_df_2023: shape={test_df_2023.shape}\")\n",
    "\n",
    "        # Dec 2022 data for seeding Jan 2023\n",
    "        dec_2022 = train_df.loc[train_df['time'].dt.to_period('M') == pd.Period('2022-12')]\n",
    "        dec_2022 = dec_2022[['lat', 'lon', target_column]].rename(columns={target_column: 'lag_1'})\n",
    "        dec_2022['Month'] = pd.Period('2023-01')\n",
    "\n",
    "        month_preds_list = []\n",
    "        unique_months_2023 = sorted(test_df_2023['Month'].unique())\n",
    "        print(f\"DEBUG: [{country}] unique_months_2023 = {unique_months_2023}\")\n",
    "\n",
    "        for i, mon in enumerate(unique_months_2023):\n",
    "            this_month_df = test_df_2023[test_df_2023['Month'] == mon].copy()\n",
    "            print(f\"DEBUG: [{country}] Month={mon}, initial this_month_df.shape = {this_month_df.shape}\")\n",
    "\n",
    "            if i == 0:\n",
    "                print(f\"DEBUG: [{country}] Merging with dec_2022: dec_2022.shape = {dec_2022.shape}\")\n",
    "                this_month_df = pd.merge(\n",
    "                    this_month_df,\n",
    "                    dec_2022[['lat', 'lon', 'lag_1']],\n",
    "                    on=['lat', 'lon'],\n",
    "                    how='left'\n",
    "                )\n",
    "                print(f\"DEBUG: [{country}] After merge (Jan 2023): this_month_df.shape = {this_month_df.shape}\")\n",
    "            else:\n",
    "                prev_month_data = month_preds_list[-1][['lat', 'lon', 'ensemble_predictions']].copy()\n",
    "                prev_month_data.rename(columns={'ensemble_predictions': 'lag_1'}, inplace=True)\n",
    "                prev_month_data['Month'] = mon\n",
    "\n",
    "                print(f\"DEBUG: [{country}] prev_month_data.shape = {prev_month_data.shape}\")\n",
    "                this_month_df = pd.merge(\n",
    "                    this_month_df,\n",
    "                    prev_month_data[['lat', 'lon', 'lag_1']],\n",
    "                    on=['lat', 'lon'],\n",
    "                    how='left'\n",
    "                )\n",
    "                print(f\"DEBUG: [{country}] After merge (Month={mon}): this_month_df.shape = {this_month_df.shape}\")\n",
    "\n",
    "            # Drop rows w/o valid lag_1\n",
    "            this_month_df.dropna(subset=['lag_1'], inplace=True)\n",
    "            print(f\"DEBUG: [{country}] After dropping NA lag_1: this_month_df.shape = {this_month_df.shape}\")\n",
    "\n",
    "            # Prepare features by dropping unwanted columns\n",
    "            X_cols_to_drop = [target_column, 'time', 'Month']\n",
    "            X_this_month = this_month_df.drop(columns=[c for c in X_cols_to_drop if c in this_month_df.columns],\n",
    "                                              errors='ignore')\n",
    "            print(f\"DEBUG: [{country}] X_this_month.shape before reindex = {X_this_month.shape}\")\n",
    "\n",
    "            # Reindex X_this_month so that it has all features used in training\n",
    "            expected_features = X_train_part.columns  # Columns from training\n",
    "            X_this_month = X_this_month.reindex(columns=expected_features, fill_value=np.nan)\n",
    "            print(f\"DEBUG: [{country}] X_this_month.shape after reindex = {X_this_month.shape}\")\n",
    "\n",
    "            # Impute missing values\n",
    "            X_this_month_imputed = imputer.transform(X_this_month)\n",
    "            X_this_month = pd.DataFrame(X_this_month_imputed, columns=expected_features, index=X_this_month.index)\n",
    "\n",
    "            # Weighted ensemble prediction\n",
    "            y_ensemble_2023, _ = predict_weighted(models, X_val_part, y_val_part, X_this_month)\n",
    "            this_month_df['ensemble_predictions'] = y_ensemble_2023\n",
    "\n",
    "            # Individual models predictions\n",
    "            for name, model in models:\n",
    "                this_month_df[f\"{name}_predictions\"] = model.predict(X_this_month)\n",
    "\n",
    "            month_preds_list.append(this_month_df)\n",
    "\n",
    "        if len(month_preds_list) > 0:\n",
    "            test_df_2023_preds = pd.concat(month_preds_list, ignore_index=True)\n",
    "            print(f\"DEBUG: [{country}] test_df_2023_preds.shape (after concat months) = {test_df_2023_preds.shape}\")\n",
    "        else:\n",
    "            test_df_2023_preds = pd.DataFrame()\n",
    "\n",
    "        # 6) Store row-level predictions\n",
    "        if not test_df_2023_preds.empty:\n",
    "            # Add 'Country' column to the row-level predictions before appending\n",
    "            test_df_2023_preds['Country'] = country\n",
    "            predictions_2023_all_countries.append(test_df_2023_preds.copy())\n",
    "\n",
    "            # 7) Monthly Aggregation\n",
    "            monthly_ensemble = (\n",
    "                test_df_2023_preds\n",
    "                .groupby(['Month', 'lat', 'lon'])['ensemble_predictions']\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "            )\n",
    "            monthly_ensemble['Country'] = country  # Ensure 'Country' is present\n",
    "            monthly_ensemble_predictions_2023.append(monthly_ensemble)\n",
    "\n",
    "            for name, _ in models:\n",
    "                col_name = f\"{name}_predictions\"\n",
    "                monthly_model = (\n",
    "                    test_df_2023_preds\n",
    "                    .groupby(['Month', 'lat', 'lon'])[col_name]\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "                monthly_model.rename(columns={col_name: 'DUSMASS_Mean_Predictions'}, inplace=True)\n",
    "        \n",
    "                # Add 'Country' column explicitly to the monthly model data\n",
    "                monthly_model['Country'] = country  \n",
    "        \n",
    "                monthly_model_predictions_2023[name].append(monthly_model)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {country}: {e}\")\n",
    "\n",
    "print(\"Main loop complete! Saving Results...\")\n",
    "\n",
    "# ------------------------- SAVE RESULTS -------------------------\n",
    "\n",
    "# 1) Feature Importances\n",
    "if all_feature_importances:\n",
    "    all_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "else:\n",
    "    all_feature_importances_df = pd.DataFrame()\n",
    "fi_output_path = os.path.join(output_dir, \"sfc_feature_importances_2023_v0063.csv\")\n",
    "all_feature_importances_df.to_csv(fi_output_path, index=False)\n",
    "print(f\"Feature importances saved to '{fi_output_path}'\")\n",
    "\n",
    "# 2) Row-Level 2023 Predictions\n",
    "if len(predictions_2023_all_countries) > 0:\n",
    "    full_predictions_2023 = pd.concat(predictions_2023_all_countries, ignore_index=True)\n",
    "    print(f\"DEBUG: [ALL] full_predictions_2023.shape = {full_predictions_2023.shape}\")\n",
    "    output_2023_path = os.path.join(output_dir, \"sfc_row_level_predictions_2023_v0063.csv\")\n",
    "    full_predictions_2023.to_csv(output_2023_path, index=False)\n",
    "    print(f\"Row-level predictions for 2023 (ensemble + individual models) saved to '{output_2023_path}'\")\n",
    "else:\n",
    "    print(\"No row-level predictions available for 2023.\")\n",
    "\n",
    "# 3) Monthly 2023 Predictions: ENSEMBLE\n",
    "if len(monthly_ensemble_predictions_2023) > 0:\n",
    "    monthly_ensemble_df_2023 = pd.concat(monthly_ensemble_predictions_2023, ignore_index=True)\n",
    "    monthly_ensemble_df_2023['Year'] = 2023\n",
    "    print(f\"DEBUG: [ALL] monthly_ensemble_df_2023.shape = {monthly_ensemble_df_2023.shape}\")\n",
    "    ensemble_monthly_output_path = os.path.join(output_dir, \"sfc_monthly_ensemble_predictions_2023_v0063.csv\")\n",
    "    monthly_ensemble_df_2023.to_csv(ensemble_monthly_output_path, index=False)\n",
    "    print(f\"Monthly ensemble predictions for 2023 saved to '{ensemble_monthly_output_path}'\")\n",
    "else:\n",
    "    print(\"No monthly ensemble predictions available for 2023.\")\n",
    "\n",
    "# 4) Monthly 2023 Predictions: INDIVIDUAL MODELS\n",
    "for name in monthly_model_predictions_2023:\n",
    "    if len(monthly_model_predictions_2023[name]) > 0:\n",
    "        model_monthly_df = pd.concat(monthly_model_predictions_2023[name], ignore_index=True)\n",
    "        model_monthly_df['Year'] = 2023\n",
    "        print(f\"DEBUG: [ALL] {name} monthly dataframe shape = {model_monthly_df.shape}\")\n",
    "        model_output_path = os.path.join(output_dir, f\"sfc_monthly_predictions_2023_{name}_v0063.csv\")\n",
    "        model_monthly_df.to_csv(model_output_path, index=False)\n",
    "        print(f\"Monthly predictions for 2023 for model '{name}' saved to '{model_output_path}'\")\n",
    "    else:\n",
    "        print(f\"No monthly predictions available for 2023 for model '{name}'.\")\n",
    "\n",
    "# 5) Model Metrics (Including Ensemble)\n",
    "if len(all_model_metrics) > 0:\n",
    "    final_metrics_df = pd.concat(all_model_metrics, ignore_index=True)\n",
    "    metrics_output_path = os.path.join(output_dir, \"sfc_model_metrics_2023_v0063.csv\")\n",
    "    final_metrics_df.to_csv(metrics_output_path, index=False)\n",
    "    print(f\"Model metrics (including Ensemble) saved to '{metrics_output_path}'\")\n",
    "else:\n",
    "    print(\"No model metrics to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e38f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Country: Yemen ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Yemen, level=10] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=10] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Yemen, level=50] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=50] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Yemen, level=100] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=100] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Yemen, level=200] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=200] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Yemen, level=300] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=300] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Yemen, level=500] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=500] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Yemen, level=700] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=700] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Yemen, level=850] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=850] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Yemen, level=925] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=925] After lag_1: shape=(526880, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Yemen, level=1000] After dropping columns: (529728, 35)\n",
      "DEBUG: [Yemen, level=1000] After lag_1: shape=(526880, 36)\n",
      ">> [Averaged] Yemen has 17088 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: Bahrain ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Bahrain, level=10] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=10] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Bahrain, level=50] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=50] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Bahrain, level=100] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=100] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Bahrain, level=200] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=200] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Bahrain, level=300] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=300] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Bahrain, level=500] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=500] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Bahrain, level=700] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=700] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Bahrain, level=850] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=850] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Bahrain, level=925] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=925] After lag_1: shape=(1110, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Bahrain, level=1000] After dropping columns: (1116, 35)\n",
      "DEBUG: [Bahrain, level=1000] After lag_1: shape=(1110, 36)\n",
      ">> [Averaged] Bahrain has 36 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: Kuwait ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Kuwait, level=10] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=10] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Kuwait, level=50] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=50] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Kuwait, level=100] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=100] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Kuwait, level=200] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=200] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Kuwait, level=300] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=300] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Kuwait, level=500] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=500] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Kuwait, level=700] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=700] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Kuwait, level=850] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=850] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Kuwait, level=925] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=925] After lag_1: shape=(20720, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Kuwait, level=1000] After dropping columns: (20832, 35)\n",
      "DEBUG: [Kuwait, level=1000] After lag_1: shape=(20720, 36)\n",
      ">> [Averaged] Kuwait has 672 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: Oman ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Oman, level=10] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=10] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Oman, level=50] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=50] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Oman, level=100] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=100] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Oman, level=200] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=200] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Oman, level=300] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=300] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Oman, level=500] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=500] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Oman, level=700] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=700] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Oman, level=850] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=850] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Oman, level=925] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=925] After lag_1: shape=(473600, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Oman, level=1000] After dropping columns: (476160, 35)\n",
      "DEBUG: [Oman, level=1000] After lag_1: shape=(473600, 36)\n",
      ">> [Averaged] Oman has 15360 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: Qatar ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Qatar, level=10] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=10] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Qatar, level=50] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=50] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Qatar, level=100] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=100] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Qatar, level=200] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=200] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Qatar, level=300] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=300] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Qatar, level=500] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=500] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Qatar, level=700] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=700] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Qatar, level=850] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=850] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Qatar, level=925] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=925] After lag_1: shape=(10360, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Qatar, level=1000] After dropping columns: (10416, 35)\n",
      "DEBUG: [Qatar, level=1000] After lag_1: shape=(10360, 36)\n",
      ">> [Averaged] Qatar has 336 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: Saudi_Arabia ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [Saudi_Arabia, level=10] After dropping columns: (2055300, 35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [Saudi_Arabia, level=10] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [Saudi_Arabia, level=50] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=50] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [Saudi_Arabia, level=100] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=100] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [Saudi_Arabia, level=200] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=200] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [Saudi_Arabia, level=300] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=300] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [Saudi_Arabia, level=500] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=500] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [Saudi_Arabia, level=700] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=700] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [Saudi_Arabia, level=850] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=850] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [Saudi_Arabia, level=925] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=925] After lag_1: shape=(2049775, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [Saudi_Arabia, level=1000] After dropping columns: (2055300, 35)\n",
      "DEBUG: [Saudi_Arabia, level=1000] After lag_1: shape=(2049775, 36)\n",
      ">> [Averaged] Saudi_Arabia has 66300 rows of final monthly predictions.\n",
      "\n",
      "--- Processing Country: United_Arab_Emirates ---\n",
      "   >> Processing Level: 10 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=10] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=10] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 50 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=50] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=50] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 100 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=100] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=100] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 200 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=200] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=200] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 300 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=300] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=300] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 500 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=500] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=500] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 700 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=700] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=700] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 850 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=850] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=850] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 925 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=925] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=925] After lag_1: shape=(103600, 36)\n",
      "   >> Processing Level: 1000 hPa\n",
      "DEBUG: [United_Arab_Emirates, level=1000] After dropping columns: (104160, 35)\n",
      "DEBUG: [United_Arab_Emirates, level=1000] After lag_1: shape=(103600, 36)\n",
      ">> [Averaged] United_Arab_Emirates has 3360 rows of final monthly predictions.\n",
      "\n",
      "Main loop complete! Saving Results...\n",
      "Feature importances saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_feature_importances_2023_v0063.csv'\n",
      "DEBUG: [ALL] full_predictions_2023.shape = (1031520, 42)\n",
      "Row-level predictions for 2023 (ensemble + individual models) saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_row_level_predictions_2023_v0063.csv'\n",
      "DEBUG: [ALL] monthly_ensemble_df_2023.shape = (1031520, 6)\n",
      "Monthly ensemble predictions for 2023 saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_ensemble_predictions_2023_v0063.csv'\n",
      "DEBUG: [ALL] lr monthly dataframe shape = (1031520, 6)\n",
      "Monthly predictions for 2023 for model 'lr' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_predictions_2023_lr_v0063.csv'\n",
      "DEBUG: [ALL] knn monthly dataframe shape = (1031520, 6)\n",
      "Monthly predictions for 2023 for model 'knn' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_predictions_2023_knn_v0063.csv'\n",
      "DEBUG: [ALL] dt monthly dataframe shape = (1031520, 6)\n",
      "Monthly predictions for 2023 for model 'dt' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_predictions_2023_dt_v0063.csv'\n",
      "DEBUG: [ALL] rf monthly dataframe shape = (1031520, 6)\n",
      "Monthly predictions for 2023 for model 'rf' saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_predictions_2023_rf_v0063.csv'\n",
      "Model metrics (including Ensemble) saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_model_metrics_2023_v0063.csv'\n",
      "Averaged ensemble predictions across levels saved to 'Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\\ua_monthly_ensemble_predictions_2023_averaged_across_levels_v0063.csv'\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Welcome to DustCast V0.0.6.3 UA! \n",
    "# This version trains on 1980-2000 and 2013-2022 Surface data and predicts DUSMASS_mean for the year 2023 by month. \n",
    "# A one-month lag is integrated so that each 2023 prediction uses the previous months value.\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    mean_squared_error\n",
    ")\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    \"\"\"Helper function to compute MSE using scikit-learn's mean_squared_error.\"\"\"\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def train_models(regressors, X_train, y_train):\n",
    "    \"\"\"Train each regressor on the training data and return the trained models.\"\"\"\n",
    "    models = []\n",
    "    for name, model in regressors:\n",
    "        model.fit(X_train, y_train)\n",
    "        models.append((name, model))\n",
    "    return models\n",
    "\n",
    "def predict_weighted(models, X_val, y_val, X_test):\n",
    "    \"\"\"\n",
    "    Compute weights for each model (inverse of MSE) on (X_val, y_val),\n",
    "    and make weighted ensemble predictions on X_test.\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    predictions = []\n",
    "\n",
    "    for name, model in models:\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        curr_mse = mse(y_val, y_pred_val)\n",
    "        # Inverse of (MSE + small constant)\n",
    "        weights.append(1 / (curr_mse + 1e-10))\n",
    "        predictions.append(model.predict(X_test))\n",
    "\n",
    "    # Normalize weights\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # Weighted average of predictions\n",
    "    predictions = np.array(predictions)  # shape: (num_models, num_samples)\n",
    "    final_prediction = np.dot(weights, predictions)\n",
    "\n",
    "    return final_prediction, weights\n",
    "\n",
    "def compute_metrics_and_weights(models, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Compute each model's MSE, MAE, R^2, and weight = 1/(MSE + 1e-10).\n",
    "    \"\"\"\n",
    "    model_names, mse_list, mae_list, r2_list, weights = [], [], [], [], []\n",
    "\n",
    "    for name, model in models:\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        curr_mse = mse(y_val, y_pred_val)\n",
    "        mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "        r2_val = r2_score(y_val, y_pred_val)\n",
    "        weight = 1 / (curr_mse + 1e-10)\n",
    "\n",
    "        model_names.append(name)\n",
    "        mse_list.append(curr_mse)\n",
    "        mae_list.append(mae_val)\n",
    "        r2_list.append(r2_val)\n",
    "        weights.append(weight)\n",
    "\n",
    "    # Normalize weights\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    return model_names, mse_list, mae_list, r2_list, weights\n",
    "\n",
    "# ------------------------- CONFIGURATION -------------------------\n",
    "base_path = r\"Z:\\Thesis\\Data\\ML_Data\\AP_ML_training_data\"\n",
    "output_dir = r\"Z:\\\\Thesis\\\\Data\\\\test\\\\DustCast\\\\UA\\\\DC_v0063\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_years = [\n",
    "    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
    "    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
    "    2000,\n",
    "    2013, 2014, 2015, 2016, 2017, 2018, 2019, \n",
    "    2020, 2021, 2022\n",
    "]\n",
    "test_year = 2023\n",
    "\n",
    "countries = [\n",
    "    \"Yemen\", \n",
    "    \"Bahrain\", \n",
    "    \"Kuwait\", \n",
    "    \"Oman\", \n",
    "    \"Qatar\", \n",
    "    \"Saudi_Arabia\", \n",
    "    \"United_Arab_Emirates\"\n",
    "]\n",
    "\n",
    "pressure_levels = [10, 50, 100, 200, 300, 500, 700, 850, 925, 1000]\n",
    "regressors = [\n",
    "    ('lr', LinearRegression(copy_X=True, fit_intercept=True)),\n",
    "    ('knn', KNeighborsRegressor(algorithm='ball_tree', leaf_size=5,\n",
    "                                n_neighbors=5, p=2, weights='distance')),\n",
    "    ('dt', DecisionTreeRegressor(max_depth=None, max_features=None,\n",
    "                                 min_samples_split=10, random_state=13)),\n",
    "    ('rf', RandomForestRegressor(max_depth=25, n_estimators=200, \n",
    "                                 max_features=0.25, min_samples_split=5, random_state=23))   \n",
    "]\n",
    "\n",
    "target_column = 'DUCMASS_mean'\n",
    "cols_to_drop = [\n",
    "    'sst_min', 'sst_max', 'sst_mean',\n",
    "    'DUCMASS25_min', 'DUCMASS25_max', 'DUCMASS25_mean',\n",
    "    'DUCMASS_min', 'DUCMASS_max', 'year', 'month',\n",
    "    'h3_res_5', 'h3_res_6', 'h3_res_5_int', 'h3_res_6_int',\n",
    "    'h3_res_3', 'h3_res_3_int', 'h3_res_4', 'h3_res_4_int'\n",
    "]\n",
    "\n",
    "# ------------------------- OUTPUT STORAGES -------------------------\n",
    "all_model_metrics = []\n",
    "all_feature_importances = []\n",
    "\n",
    "# For monthly predictions across all countries/levels\n",
    "monthly_ensemble_predictions_all = []\n",
    "monthly_model_predictions_all = {name: [] for name, _ in regressors}\n",
    "\n",
    "# For 2023 predictions (row-level, monthly, etc.)\n",
    "predictions_2023_all_countries = []  # row-level 2023 predictions\n",
    "monthly_ensemble_predictions_2023 = []  # monthly ensemble for 2023\n",
    "monthly_model_predictions_2023 = {name: [] for name, _ in regressors}  # monthly predictions per model for 2023\n",
    "\n",
    "# For averaged ensemble across levels\n",
    "predictions_all_countries_across_levels = []\n",
    "\n",
    "# ------------------------- MAIN LOOP -------------------------\n",
    "for country in countries:\n",
    "    print(f\"\\n--- Processing Country: {country} ---\")\n",
    "\n",
    "    # Will store the final test predictions across all levels for this country\n",
    "    predictions_all_levels_country = []\n",
    "\n",
    "    for level in pressure_levels:\n",
    "        print(f\"   >> Processing Level: {level} hPa\")\n",
    "        try:\n",
    "            # 1) LOAD & COMBINE TRAIN DATA\n",
    "            train_frames = []\n",
    "            for yr in train_years:\n",
    "                file_path = os.path.join(base_path, str(yr), f\"{country}_{yr}_pressure_monthly_stats_merged.parquet\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"Training file not found: {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                df_temp = pd.read_parquet(file_path)\n",
    "                df_temp['time'] = pd.to_datetime(df_temp['time'])\n",
    "\n",
    "                # Keep only rows for the current pressure level\n",
    "                df_temp = df_temp[df_temp['level'] == level]\n",
    "                if df_temp.empty:\n",
    "                    continue\n",
    "\n",
    "                train_frames.append(df_temp)\n",
    "\n",
    "            if not train_frames:\n",
    "                print(f\"       No training data for {country}, level {level}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            train_df = pd.concat(train_frames, ignore_index=True)\n",
    "            train_df['Country'] = country\n",
    "\n",
    "            # Drop unnecessary columns\n",
    "            train_df.drop(columns=[c for c in cols_to_drop if c in train_df.columns],\n",
    "                          inplace=True, errors='ignore')\n",
    "            print(f\"DEBUG: [{country}, level={level}] After dropping columns: {train_df.shape}\")\n",
    "\n",
    "            # Sort & create lag_1 by grouping on (lat, lon, level)\n",
    "            train_df = train_df.sort_values(by=['lat', 'lon', 'level', 'time'])\n",
    "            train_df['lag_1'] = train_df.groupby(['lat', 'lon', 'level'])[target_column].shift(1)\n",
    "            train_df.dropna(subset=[target_column, 'lag_1'], inplace=True)\n",
    "            print(f\"DEBUG: [{country}, level={level}] After lag_1: shape={train_df.shape}\")\n",
    "\n",
    "            # 2) PREPARE TRAIN FEATURES/TARGET\n",
    "            X_train_full = train_df.drop(columns=[target_column, 'time', 'Country'], errors='ignore')\n",
    "            y_train_full = train_df[target_column]\n",
    "\n",
    "            # 3) Train-Validation Split\n",
    "            X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(\n",
    "                X_train_full, y_train_full, test_size=0.3, random_state=42\n",
    "            )\n",
    "\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_train_part_imp = imputer.fit_transform(X_train_part)\n",
    "            X_val_part_imp   = imputer.transform(X_val_part)\n",
    "\n",
    "            X_train_part = pd.DataFrame(X_train_part_imp, columns=X_train_part.columns, index=X_train_part.index)\n",
    "            X_val_part   = pd.DataFrame(X_val_part_imp,   columns=X_val_part.columns,   index=X_val_part.index)\n",
    "\n",
    "            # 4) Train Models\n",
    "            models = train_models(regressors, X_train_part, y_train_part)\n",
    "\n",
    "            # 4.1) Compute & Store Model Metrics\n",
    "            model_names, mse_list, mae_list, r2_list, weights_array = compute_metrics_and_weights(\n",
    "                models, X_val_part, y_val_part\n",
    "            )\n",
    "            metrics_df = pd.DataFrame({\n",
    "                'Country': country,\n",
    "                'Level': level,\n",
    "                'Model': model_names,\n",
    "                'MSE': mse_list,\n",
    "                'MAE': mae_list,\n",
    "                'R2': r2_list,\n",
    "                'Weight': weights_array\n",
    "            })\n",
    "\n",
    "            # Ensemble metrics\n",
    "            ensemble_val_preds, _ = predict_weighted(models, X_val_part, y_val_part, X_val_part)\n",
    "            ensemble_mse_val = mse(y_val_part, ensemble_val_preds)\n",
    "            ensemble_mae_val  = mean_absolute_error(y_val_part, ensemble_val_preds)\n",
    "            ensemble_r2_val   = r2_score(y_val_part, ensemble_val_preds)\n",
    "\n",
    "            ensemble_row = {\n",
    "                'Country': country,\n",
    "                'Level': level,\n",
    "                'Model': 'ensemble',\n",
    "                'MSE': ensemble_mse_val,\n",
    "                'MAE': ensemble_mae_val,\n",
    "                'R2': ensemble_r2_val,\n",
    "                'Weight': 1.0\n",
    "            }\n",
    "            ensemble_df = pd.DataFrame([ensemble_row])\n",
    "            metrics_df = pd.concat([metrics_df, ensemble_df], ignore_index=True)\n",
    "            all_model_metrics.append(metrics_df)\n",
    "\n",
    "            # 5) Prepare Test Data for 2023 (Monthly Approach)\n",
    "            test_file_path = os.path.join(\n",
    "                base_path, str(test_year), f\"{country}_{test_year}_pressure_monthly_stats_merged.parquet\"\n",
    "            )\n",
    "            if not os.path.exists(test_file_path):\n",
    "                print(f\"       Test file not found for {country}, level {level}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            test_df_2023 = pd.read_parquet(test_file_path)\n",
    "            test_df_2023['time'] = pd.to_datetime(test_df_2023['time'])\n",
    "            test_df_2023 = test_df_2023[test_df_2023['level'] == level]\n",
    "            if test_df_2023.empty:\n",
    "                print(f\"       No 2023 data for {country}, level {level}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            test_df_2023.drop(columns=[c for c in cols_to_drop if c in test_df_2023.columns],\n",
    "                              inplace=True, errors='ignore')\n",
    "            test_df_2023 = test_df_2023.sort_values(by=['lat', 'lon', 'level', 'time'])\n",
    "            test_df_2023['Month'] = test_df_2023['time'].dt.to_period('M')\n",
    "\n",
    "            # Dec 2022 data to seed Jan 2023\n",
    "            dec_2022 = train_df.loc[train_df['time'].dt.to_period('M') == pd.Period('2022-12')]\n",
    "            dec_2022 = dec_2022[['lat', 'lon', 'level', target_column]]\\\n",
    "                .rename(columns={target_column: 'lag_1'})\n",
    "            dec_2022['Month'] = pd.Period('2023-01')\n",
    "\n",
    "            # We'll hold month-by-month predictions here\n",
    "            month_preds_list = []\n",
    "            unique_months_2023 = sorted(test_df_2023['Month'].unique())\n",
    "\n",
    "            for i, mon in enumerate(unique_months_2023):\n",
    "                this_month_df = test_df_2023[test_df_2023['Month'] == mon].copy()\n",
    "\n",
    "                if i == 0:\n",
    "                    this_month_df = pd.merge(\n",
    "                        this_month_df,\n",
    "                        dec_2022[['lat', 'lon', 'level', 'lag_1']],\n",
    "                        on=['lat', 'lon', 'level'],\n",
    "                        how='left'\n",
    "                    )\n",
    "                else:\n",
    "                    # Merge in the previous month's ensemble predictions as 'lag_1'\n",
    "                    prev_data = month_preds_list[-1][['lat', 'lon', 'level', 'ensemble_predictions']]\\\n",
    "                        .rename(columns={'ensemble_predictions': 'lag_1'})\n",
    "                    prev_data['Month'] = mon\n",
    "\n",
    "                    this_month_df = pd.merge(\n",
    "                        this_month_df,\n",
    "                        prev_data[['lat', 'lon', 'level', 'lag_1']],\n",
    "                        on=['lat', 'lon', 'level'],\n",
    "                        how='left'\n",
    "                    )\n",
    "\n",
    "                # Drop rows w/o valid lag_1\n",
    "                this_month_df.dropna(subset=['lag_1'], inplace=True)\n",
    "\n",
    "                # Prepare X by dropping target, time, Country, Month\n",
    "                X_cols_drop = [target_column, 'time', 'Country', 'Month']\n",
    "                X_this_month = this_month_df.drop(\n",
    "                    columns=[c for c in X_cols_drop if c in this_month_df.columns],\n",
    "                    errors='ignore'\n",
    "                )\n",
    "\n",
    "                # === HadISST1.1 Handling: Reindex to match training features ===\n",
    "                expected_features = X_train_part.columns\n",
    "                X_this_month = X_this_month.reindex(columns=expected_features, fill_value=np.nan)\n",
    "\n",
    "                # Impute missing values\n",
    "                X_this_month_imp = imputer.transform(X_this_month)\n",
    "                X_this_month = pd.DataFrame(X_this_month_imp, columns=expected_features, index=X_this_month.index)\n",
    "\n",
    "                # Weighted ensemble prediction\n",
    "                y_ensemble, _ = predict_weighted(models, X_val_part, y_val_part, X_this_month)\n",
    "                this_month_df['ensemble_predictions'] = y_ensemble\n",
    "\n",
    "                # === Row-level MSE Calculation ===\n",
    "                if target_column in this_month_df.columns:\n",
    "                    this_month_df['squared_error_ensemble'] = (this_month_df[target_column] - y_ensemble)**2\n",
    "\n",
    "                # Individual model predictions\n",
    "                for name, model in models:\n",
    "                    this_month_df[f\"{name}_predictions\"] = model.predict(X_this_month)\n",
    "\n",
    "                month_preds_list.append(this_month_df)\n",
    "\n",
    "            # Combine monthly predictions for this level\n",
    "            if month_preds_list:\n",
    "                test_2023_preds = pd.concat(month_preds_list, ignore_index=True)\n",
    "            else:\n",
    "                test_2023_preds = pd.DataFrame()\n",
    "\n",
    "            if not test_2023_preds.empty:\n",
    "                # Store row-level predictions for this level\n",
    "                predictions_all_levels_country.append(test_2023_preds.copy())\n",
    "                predictions_2023_all_countries.append(test_2023_preds.copy())\n",
    "\n",
    "                # Monthly ensemble predictions for this level\n",
    "                monthly_ensemble = (\n",
    "                    test_2023_preds\n",
    "                    .groupby(['Month', 'lat', 'lon', 'level'])['ensemble_predictions']\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "                monthly_ensemble_predictions_all.append(monthly_ensemble)\n",
    "                monthly_ensemble_predictions_2023.append(monthly_ensemble.copy())\n",
    "\n",
    "                # Monthly predictions per model for this level\n",
    "                for name, _ in models:\n",
    "                    col_name = f\"{name}_predictions\"\n",
    "                    monthly_model = (\n",
    "                        test_2023_preds\n",
    "                        .groupby(['Month', 'lat', 'lon', 'level'])[col_name]\n",
    "                        .mean()\n",
    "                        .reset_index()\n",
    "                    )\n",
    "                    monthly_model.rename(columns={col_name: 'DUCMASS_Mean_Predictions'}, inplace=True)\n",
    "\n",
    "                    monthly_model_predictions_all[name].append(monthly_model)\n",
    "                    monthly_model_predictions_2023[name].append(monthly_model.copy())\n",
    "\n",
    "            # 6) Feature Importances\n",
    "            feature_importances = pd.DataFrame(index=X_train_part.columns)\n",
    "            for name, model in models:\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    feature_importances[name] = model.feature_importances_\n",
    "\n",
    "            if not feature_importances.empty:\n",
    "                feature_importances.reset_index(inplace=True)\n",
    "                feature_importances.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "                feature_importances['Country'] = country\n",
    "                feature_importances['Level']   = level\n",
    "                all_feature_importances.append(feature_importances)\n",
    "            else:\n",
    "                print(f\"Warning: No feature importances for {country}, level {level}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"       Error processing {country}, level {level}: {e}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # AFTER processing all levels for this country, combine & average\n",
    "    # -----------------------------------------------------------------\n",
    "    if predictions_all_levels_country:\n",
    "        # 1) Concatenate data across all pressure levels\n",
    "        combined_across_levels = pd.concat(predictions_all_levels_country, ignore_index=True)\n",
    "\n",
    "        # 2) Calculate mean of 'ensemble_predictions' across levels\n",
    "        average_ensemble = (\n",
    "            combined_across_levels\n",
    "            .groupby(['lat', 'lon', 'Month'], as_index=False)['ensemble_predictions']\n",
    "            .mean()\n",
    "        )\n",
    "        average_ensemble.rename(\n",
    "            columns={'ensemble_predictions': 'ensemble_prediction_across_levels'},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # Store for final \"averaged\" results across levels\n",
    "        predictions_all_countries_across_levels.append(average_ensemble)\n",
    "        print(f\">> [Averaged] {country} has {average_ensemble.shape[0]} rows of final monthly predictions.\")\n",
    "\n",
    "print(\"\\nMain loop complete! Saving Results...\")\n",
    "\n",
    "# ------------------------- SAVE RESULTS -------------------------\n",
    "\n",
    "# 1) Feature Importances\n",
    "if all_feature_importances:\n",
    "    all_feature_importances_df = pd.concat(all_feature_importances, ignore_index=True)\n",
    "else:\n",
    "    all_feature_importances_df = pd.DataFrame()\n",
    "\n",
    "fi_output_path = os.path.join(output_dir, \"ua_feature_importances_2023_v0063.csv\")\n",
    "all_feature_importances_df.to_csv(fi_output_path, index=False)\n",
    "print(f\"Feature importances saved to '{fi_output_path}'\")\n",
    "\n",
    "# 2) Row-Level 2023 Predictions\n",
    "if len(predictions_2023_all_countries) > 0:\n",
    "    full_predictions_2023 = pd.concat(predictions_2023_all_countries, ignore_index=True)\n",
    "    print(f\"DEBUG: [ALL] full_predictions_2023.shape = {full_predictions_2023.shape}\")\n",
    "    output_2023_path = os.path.join(output_dir, \"ua_row_level_predictions_2023_v0063.csv\")\n",
    "    full_predictions_2023.to_csv(output_2023_path, index=False)\n",
    "    print(f\"Row-level predictions for 2023 (ensemble + individual models) saved to '{output_2023_path}'\")\n",
    "else:\n",
    "    print(\"No row-level predictions available for 2023.\")\n",
    "\n",
    "# 3) Monthly 2023 Predictions: ENSEMBLE\n",
    "if len(monthly_ensemble_predictions_2023) > 0:\n",
    "    monthly_ensemble_df_2023 = pd.concat(monthly_ensemble_predictions_2023, ignore_index=True)\n",
    "    monthly_ensemble_df_2023['Year'] = 2023\n",
    "    print(f\"DEBUG: [ALL] monthly_ensemble_df_2023.shape = {monthly_ensemble_df_2023.shape}\")\n",
    "    ensemble_monthly_output_path = os.path.join(output_dir, \"ua_monthly_ensemble_predictions_2023_v0063.csv\")\n",
    "    monthly_ensemble_df_2023.to_csv(ensemble_monthly_output_path, index=False)\n",
    "    print(f\"Monthly ensemble predictions for 2023 saved to '{ensemble_monthly_output_path}'\")\n",
    "else:\n",
    "    print(\"No monthly ensemble predictions available for 2023.\")\n",
    "\n",
    "# 4) Monthly 2023 Predictions: INDIVIDUAL MODELS\n",
    "for name in monthly_model_predictions_2023:\n",
    "    if len(monthly_model_predictions_2023[name]) > 0:\n",
    "        model_monthly_df = pd.concat(monthly_model_predictions_2023[name], ignore_index=True)\n",
    "        model_monthly_df['Year'] = 2023\n",
    "        print(f\"DEBUG: [ALL] {name} monthly dataframe shape = {model_monthly_df.shape}\")\n",
    "        model_output_path = os.path.join(output_dir, f\"ua_monthly_predictions_2023_{name}_v0063.csv\")\n",
    "        model_monthly_df.to_csv(model_output_path, index=False)\n",
    "        print(f\"Monthly predictions for 2023 for model '{name}' saved to '{model_output_path}'\")\n",
    "    else:\n",
    "        print(f\"No monthly predictions available for 2023 for model '{name}'.\")\n",
    "\n",
    "# 5) Model Metrics (Including Ensemble)\n",
    "if len(all_model_metrics) > 0:\n",
    "    final_metrics_df = pd.concat(all_model_metrics, ignore_index=True)\n",
    "    metrics_output_path = os.path.join(output_dir, \"ua_model_metrics_2023_v0063.csv\")\n",
    "    final_metrics_df.to_csv(metrics_output_path, index=False)\n",
    "    print(f\"Model metrics (including Ensemble) saved to '{metrics_output_path}'\")\n",
    "else:\n",
    "    print(\"No model metrics to save.\")\n",
    "\n",
    "# 6) Monthly 2023 Predictions: AVERAGED ACROSS LEVELS\n",
    "if len(predictions_all_countries_across_levels) > 0:\n",
    "    final_averages_df = pd.concat(predictions_all_countries_across_levels, ignore_index=True)\n",
    "    final_averages_df['Year'] = 2023\n",
    "\n",
    "    final_averages_output_path = os.path.join(\n",
    "        output_dir,\n",
    "        \"ua_monthly_ensemble_predictions_2023_averaged_across_levels_v0063.csv\"\n",
    "    )\n",
    "    final_averages_df.to_csv(final_averages_output_path, index=False)\n",
    "    print(f\"Averaged ensemble predictions across levels saved to '{final_averages_output_path}'\")\n",
    "else:\n",
    "    print(\"No averaged ensemble predictions across levels available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f33b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
